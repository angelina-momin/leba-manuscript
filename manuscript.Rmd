---
title             : "_Light Exposure Behavior Assessment (LEBA)_: Development of a novel instrument to capture light exposure-related behaviours"
shorttitle        : "LEBA"

author: 
  - name          : "Mushfiqul Anwar Siraji"
    affiliation   : "1, *"
    email         : "mushfiqul.anwarsiraji@monash.edu"
    role:         
      - Formal Analysis
      - Visualization
      - Writing – original draft
      - Writing – review & editing;
       
  - name          : "Rafael Robert Lazar"
    affiliation   : "2, 3, *"
    role:
      - Data curation
      - Investigation
      - Project administration
      - Visualization
      - Writing – original draft
      - Writing – review & editing;
      
  - name          : "Juliëtte	van Duijnhoven"
    affiliation   : "4, 5"
    email         : "j.v.duijnhoven1@tue.nl"
    role:         
      - Conceptualization
      - Methodology
      - Investigation
      - Writing – review & editing

  - name          : "Luc Schlangen"
    affiliation   : "5, 6"
    email         : "l.j.m.schlangen@tue.nl"
    role:         
      - Conceptualization
      - Methodology
      - Investigation
      - Writing – review & editing

  - name          : "Shamsul Haque"
    affiliation   : "1"
    email         : "shamsul@monash.edu"
    role:         
      - Conceptualization
      - Supervision
      - Writing – review & editing
      
  - name          : "Vineetha Kalavally"
    affiliation   : "7"
    email         : "vineetha@monash.edu"
    role:         
      - Supervision
      - Writing – review & editing
      
  - name          : "Céline Vetter"
    affiliation   : "8, 9"
    email         : "celine.vetter@colorado.edu"
    role:         
      - Conceptualization
      - Writing – review & editing
      
  - name          : "Gena Glickman"
    affiliation   : "10"
    email         : "gena.glickman@usuhs.edu"
    role:         
      - Conceptualization
      - Methodology
      - Writing – review & editing
      
  - name          : "Karin Smolders"
    affiliation   : "5,6"
    email         : "k.c.h.j.smolders@tue.nl"
    role:         
      - Conceptualization
      - Methodology
      - Writing – review & editing

  - name          : "Manuel Spitschan"
    corresponding : yes
    affiliation   : "11, 12, 13"
    email         : "manuel.spitschan@tum.de "
    role:         
      - Conceptualization
      - Data curation
      - Investigation
      - Project administration
      - Visualization
      - Methodology
      - Writing – original draft
      - Writing – review & editing

affiliation:
  - id            : "1"
    institution   : "Monash University, Department of Psychology, Jeffrey Cheah School of Medicine and Health Sciences, Malaysia"
  - id            : "2"
    institution   : "Psychiatric Hospital of the University of Basel (UPK), Centre for Chronobiology, Basel, Switzerland"
  - id            : "3"
    institution   : "University of Basel, Transfaculty Research Platform Molecular and Cognitive Neurosciences, Basel, Switzerland"
  - id            : "4"
    institution   : "Eindhoven University of Technology, Department of the Built Environment, Building Lighting, Eindhoven, Netherlands"
  - id            : "5"
    institution   : "Eindhoven University of Technology, Intelligent Lighting Institute, Eindhoven, Netherlands"
  - id            : "6"
    institution   : "Eindhoven University of Technology, Department of Industrial Engineering and Innovation Sciences, Human-Technology Interaction, Eindhoven, Netherlands"
  - id            : "7"
    institution   : "Monash University, Department of Electrical and Computer Systems Engineering, Selangor, Malaysia"
  - id            : "8"
    institution   : "University of Colorado Boulder, Department of Integrative Physiology, Boulder, USA"

  - id            : "9"
    institution   : "XIMES GmbH, Vienna, Austria"
  - id            : "10"
    institution   : "Uniformed Services University of the Health Sciences, Department of Psychiatry, Bethesda, USA"   
  - id            : "11"
    institution   : "Max Planck Institute for Biological Cybernetics, Tübingen, Germany"
  - id            : "12"
    institution   : "Technical University of Munich, Department of Sport and Health Sciences (TUM SG), Munich, Germany"
  - id            : "13"
    institution   : "University of Oxford, Department of Experimental Psychology, Oxford, United Kingdom"
  - id            : "*"
    institution   : "Joint first author"   


authornote: |
  This research is supported by funding from the Welcome Trust (204686/Z/16/Z), the European Training Network LIGHTCAP (project number 860613) under the Marie Skłodowska-Curie actions framework H2020-MSCA-ITN-2019, the BioClock project (number 1292.19.077) of the research program Dutch Research Agenda: Onderzoek op Routes door Consortia (NWA-ORC) which is (partly) financed by the Dutch Research Council (NWO), and the European Union and the nationals contributing in the context of the ECSEL Joint Undertaking programme (2021-2024) under the grant #101007319.



abstract: |
  Light exposure is an important driver of health and well-being. Many aspects of light exposure are modulated by our behaviour. How these light-related behaviours can be shaped to optimise personal light exposure is currently unknown. Here, we present a novel, self-reported and psychometrically validated instrument to capture light exposure-related behaviour, the Light Exposure Behavior Assessment (LEBA). 
  An expert panel prepared the initial 48 item pool. Responses to these items were then collected in an online survey producing responses from an international sample (690 completed responses, 74 countries, 28 time zones). Exploratory factor analysis on an initial subset of our sample (n=428) rendered a five-factor solution with 25 items (Wearing blue light filters, spending time outdoors, using phone and smart-watch in bed, using light before bedtime, using light in the morning and during daytime). Confirmatory factor analysis on another subset of participants (n=262) yielded the best fit for the five-factor solution after discarding another two items (CFI=0.97, TLI=0.96, RMSEA=0.05, SRMR=0.09). The internal consistency reliability coefficient for the total instrument was McDonald’s omega =0.73. Measurement model invariance analysis between native and non-native English speakers showed our model attained the highest level of invariance (residual invariance; CFI=0.95, TLI =0.95, RMSEA=0.05). Lastly, a short form of LEBA (n=18) was developed using Item Response Theory on the complete sample (n=690). 
  The psychometric properties of the LEBA instrument indicate the usability to measure the light exposure-related behaviours across a variety of settings and may offer a scalable solution to characterize light exposure-related behaviours in remote samples.

  
keywords          : "light exposure, light-related behaviours, non-visual effects of light, psychometrics"
wordcount         : "X"

bibliography      : ["references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no


documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    keep_tex: true
    latex_engine: xelatex
    includes:
      in_header: header.tex
appendix:
  - "appendix-1.Rmd"
  - "appendix-2.Rmd"
  - "appendix-3.Rmd"
mainfont: Arial
---

```{r setup, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = F, message = F, dpi=600, fig.width = 6,
 fig.asp = 0.8,out.width = "80%", dev=c('png','postscript'))
#options(knitr.duplicate.label = "allow")
set.seed(123)
par(family = "Arial")
```

```{r pacman, eval=FALSE, include=FALSE}
#You need to run this chunk 1X in your system 
#install.packages("pacman")#Run this if you don't have pacman installed.
pacman::p_load(MOTE, tidyverse, psych, lavaan,kableExtra,gt,gtsummary, mirt,likert,kutils,semPlot,semTable,semTools,ggcorrplot,dlookr,qgraph,paran,EFA.MRFA,VIM,DiagrammeR,DiagrammeRsvg,ggplot2,cowplot,rsvg,questionr,magick, simsem,readxl, stringr,RColorBrewer,WrightMap,huxtable,tikzDevice)
pacman::p_install_gh("jthomasmock/gtExtras")
pacman::p_install_gh("crsh/papaja")
pacman::p_install_gh("masiraji/tabledown")
pacman::p_install_gh("crsh/citr")
devtools::install_github("unDocUMeantIt/koRpus")
koRpus::install.koRpus.lang(lang=c("en"))


#if you dont have LaTeX installed run the following lines
#install.packages("tinytex")
#tinytex::install_tinytex()
```

```{r library, include=FALSE}

library(papaja) # devtools::install_github("crsh/papaja")
library(lavaan)
library(semPlot) #devtools::install_github('SachaEpskamp/semPlot',  dependencies = T)
library(semTools)
library(MOTE)
library(car)#reversecoding 
library(psych)
library(dlookr)
library(plyr)
library(tidyverse)
library(qgraph)
library(kableExtra)
library(paran) # Parallel analysis
library(EFA.MRFA) # Hull method
library(DiagrammeR) #devtools::install_github('rich-iannone/DiagrammeR')
library(DiagrammeRsvg) #For DiagrammeR
library(rsvg) #For DiagrammeR
library(ggcorrplot)
library(semTable)
library(magick)
library(mirt)
library(gtsummary)
library(gt)
library(gtExtras)
library(likert)
library(VIM) #Missing data
library(kutils)
library(simsem)
library(tabledown)
library(readxl)
library(koRpus)# stable release
library(koRpus.lang.en)
r_refs("references.bib")
```

---
nocite: |
  `r cite_r("references.bib")`
  [@verriotto2017new][@eklund1996development][@bajaj2011validation][@dianat2013objective]
  [@horne1976self][@roenneberg2003life][@Olivier.2016][@buysse1989pittsburgh][@Xie.2021][@bossini2006sensibilita]
---

# Introduction

-   Light exposure is important

-   Light exposure Behavior is important

-   Table: Overview Existing Related Scales: items in total / items on light exposure (behaviour)

-   Existing Scales: Review them in text

-   None of these do light exposure behavior.

```{r relscale, include=F, warning=F, message=F}

relevant.scale.data <- readxl::read_excel("Table_raw/relevant_scales.xlsx")

```


```{r reltab2, results='asis'}
relevant.scale.data %>% 
apa_table(landscape =T,caption ="Releated Scales", format = "latex",escape = T, font_size = "footnotesize", align = c("p{3cm}", rep("p{3.6cm}", ncol(relevant.scale.data)))) 
```


# Methods
## Ethical approval

The cantonal ethics commission (Ethikkommission Nordwest- und Zentralschweiz, project ID Req-2021-00488) reviewed this project and issued an official clarification of responsibility (full document see Suppl. Fig X in appendix) stating: "The research project does not fall under the scope of the Human Research Act, because your project is using only anonymised data. An authorisation from the ethics committee is therefore not required and the EKNZ is not responsible for its review."

## Data Availability

All code and data underlying this article is available on a public GitHub repository (https://github.com/leba-instrument/leba-manuscript).


## Survey characteristics

Data was collected in a quantitative cross-sectional approach via a fully anonymous online survey hosted on REDCap [@harris2009research; @harris2019redcap] by way of the University of Basel [sciCORE](https://redcap.scicore.unibas.ch). Participants were recruited via the [website](https://enlightenyourclock.org/participate-in-research) of a Comic co-released with the survey[@Weinzaepflen.2021] , social media (i.e., LinkedIn, Twitter, Facebook), mailing lists, word of mouth, the investigators' personal contacts, and supported by distribution of the survey link via f.lux software [@f.lux].

Completing the online survey took approx. 15 to 20 minutes and was not compensated. The first page of the survey comprised a participant information sheet, where participants' informed consent to participate was obtained before any of the questions were displayed. Underaged participants (<18 years) were urged to obtain assent from their parents/legal guardians, before filling in the survey. Information on the first page included the objectives of the study, inclusion criteria, estimated duration, the use, storage and sharing of the data, compensation (none), and information about the type of questions in the survey. Moreover, participants needed to confirm that they were participating the survey for the first time. To ensure high data quality, five attention check items were included in the survey (e.g., "We want to make sure you are paying attention. What is 4+5?"). The data analysed in this study was collected between 17.05.2021 and 03.09.2021. Questions incorporating retrospective recall were all aligned to the period of "past four weeks", matching the presented LEBA instrument.

In addition to the LEBA questionnaire, which is subject of the current study, the following variables and items were assessed but not included in the analysis:

-   Sleep disturbance and sleep-related impairment (adult and pediatric versions) [@Bevans.2019; @Buysse.2010; @Forrest.2018; @Harb.2015; @Yu.2011]
-   Sleep duration, timing, and latency, chronotype, social jetlag, time in bed, work/sleep schedule and outdoor light exposure duration (version for adults and adolescents) [@roenneberg2003life]
-   Sleep environment [@Olivier.2016]
-   Meal timing & caffeine consumption [custom items]
-   Light sensitivity (photophobia vs. photophilia) [@Wu.2017]
-   Self-reported pubertal stage (only if younger than 18 years old) [@Petersen.1988]

Furthermore, the following 1-item demographic variables were assessed:

-   Age
-   Sex
-   Gender identity
-   Occupational Status
-   COVID-19 related Occupational setting during the past four weeks
-   Time zone & country of residence
-   English as native language

## Participants

```{r Data, include=FALSE}
data <- readRDS("leba_2021-09-08.rds")

# Separating EFA and CFA samples with descriptive column
descriptives.data <- data

## Merge "0"s and "1"s into "1"s select,subset assign)
descriptives.data[ , 9:56 ][ descriptives.data[ , 9:56 ] == 0 ] <- 1
#EFA.descriptives <- descriptives.data[1:428,]
EFA.descriptives <- subset(descriptives.data, IncludedInEFA == "TRUE")
#CFA.descriptives <- descriptives.data[429:690, ]
CFA.descriptives<- subset(descriptives.data, IncludedInEFA == "FALSE")

#Separating the EFA and CFA(only items)
sem.data <- data[, 9:56] #EFA & CFA data
sem.data[ sem.data == 0] <- 1 #Merged "0"s and "1"s into "1"s

## renaming the column-header
prefix <- "item"
sufix <- c(1:48)
colnam <- paste(prefix,sufix, sep = "" )
colnames(sem.data) <- colnam
names(sem.data)[names(sem.data) == "item1"] <- "item01"
names(sem.data)[names(sem.data) == "item2"] <- "item02"
names(sem.data)[names(sem.data) == "item3"] <- "item03"
names(sem.data)[names(sem.data) == "item4"] <- "item04"
names(sem.data)[names(sem.data) == "item5"] <- "item05"
names(sem.data)[names(sem.data) == "item6"] <- "item06"
names(sem.data)[names(sem.data) == "item7"] <- "item07"
names(sem.data)[names(sem.data) == "item8"] <- "item08"
names(sem.data)[names(sem.data) == "item9"] <- "item09"
```

```{r country, include=FALSE}
library(stringr)
country <- data

TZ <- as.data.frame(str_split_fixed(country$slypos_demographics_tz.factor, "-", 2))

num.countries <- unique(TZ$V1)
num.Timezone <- unique(TZ$V2)

UTC <- as.data.frame(str_split_fixed(TZ$V2, "UTC", 2))
numUTC <- unique(UTC$V2)
```

```{r prepareDescTable, include=FALSE}

listdescVars <- colnames(descriptives.data[c(1:3,5:7)])


#seperating naming and  reducing data for descriptive Table 
desctable.data <- dplyr::select(descriptives.data, c(listdescVars,
                          IncludedInCFA))

#renaming TRUE and FALSE from the IncludedInCFA to EFA and CFA for Descriptive Table
desctable.data$IncludedInCFA[desctable.data$IncludedInCFA == T ] <-
 "2. CFA Sample"
desctable.data$IncludedInCFA[desctable.data$IncludedInCFA == F ] <- 
 "1. EFA Sample"

# recode the Gender factor so it will only show "Gender Diverse" in the summary table
desctable.data$slypos_demographics_gender.factor <-
  recode_factor(desctable.data$slypos_demographics_gender.factor, "No" = "Yes",
         "Yes"= "No")
       
# create descriptive table for the demographic vars (excluding tz & Country) with gtsummary
desctable.data %>%
  tbl_summary(
    by = IncludedInCFA,
    statistic = list(all_continuous() ~ "{mean} ({sd})",
                     all_categorical() ~ "{n} ({p}%)"),
    digits = all_continuous() ~ 2,
    label = list(slypos_demographics_age ~ "Age",
                 slypos_demographics_sex.factor ~ "Sex",
                 slypos_demographics_gender.factor ~ "Gender-Variant Identity",
                 slypos_demographics_language.factor ~ "Native English Speaker",
                 slypos_demographics_work_or_school.factor ~ "Occupational Status",
                 slypos_demographics_school.factor ~ "Occupational setting"
                 ),
    missing = "no"
    ) %>% add_overall() %>% bold_labels() %>% add_p() %>% add_q() %>%
modify_header(label ~ "**Variable**") %>% separate_p_footnotes() %>%
  modify_caption("Demographic Characteristics") -> desc_table 

as_tibble(desc_table) -> desc_tibble 
as_kable_extra(desc_table, format = "latex",booktabs = T) -> desc_kable #save it as a knitr::kable

#summarise country/time zone data

descriptives.data%>%
  tbl_summary(
    label = slypos_demographics_tz.factor ~ "Time zone - Country",
    statistic = list(all_categorical() ~ "{n} ({p}%)"),
    missing = "no",
    sort = all_categorical() ~ "frequency",
    include = "slypos_demographics_tz.factor"
  )  %>% bold_labels() %>% 
  modify_header(label ~ "") %>%
  as_tibble(format = 'pipe') -> tz_tibble

```

```{r demographics, warning=F, message=F}
desc_kable %>% 
  kable_styling(latex_options = c("scale_down")) 
```

Table 2 summarizes the survey participants' demographic characteristics. Only participants completing the full LEBA questionnaire were included, thus there are no missing values in the item analyses. XX participants were excluded from analysis due to not passing at least one of the "attention check" items. For exploring initial factor structure (EFA) , a sample of 250-300 is recommended [@comreyFirstCourseFactor1992; @schonbrodtWhatSampleSize2013]. For estimating the sample size for the confirmatory factor analysis (CFA) we followed the N:q rule [@bentlerPracticalIssuesStructural1987; @jacksonRevisitingSampleSize2003; @klinePrinciplesPracticeStructural2015; @worthingtonScaleDevelopmentResearch2006], where ten participants per parameter is required to earn trustworthiness of the result. Our sample size exceeds these requirements: Anonymous responses from a total of *n* = `r nrow(desctable.data)` participants were included in the analysis of the current study, split into samples for exploratory (EFA: *n* = `r nrow(desctable.data[desctable.data$IncludedInCFA == "1. EFA Sample",])`) and confirmatory factor analysis (CFA: *n* = `r nrow(desctable.data[desctable.data$IncludedInCFA == "2. CFA Sample",])`). The EFA sample included participants filling out the questionnaire from 17.05.2021 to XX.XX.XXXX , whereas participants who filled out the questionnaire from YY.YY.YYYY to 03.09.2021 were included in the CFA analysis. Participants indicated filling out the online survey from a diverse range of geographic locations. The ten most common country + timezone combinations included:

- `r tz_tibble[2,1]`:     `r tz_tibble[2,2]` 
- `r tz_tibble[3,1]`:     `r tz_tibble[3,2]`
- `r tz_tibble[4,1]`:     `r tz_tibble[4,2]`
- `r tz_tibble[5,1]`:     `r tz_tibble[5,2]`
- `r tz_tibble[6,1]`:     `r tz_tibble[6,2]`
- `r tz_tibble[7,1]`:     `r tz_tibble[7,2]`
- `r tz_tibble[8,1]`:     `r tz_tibble[8,2]`
- `r tz_tibble[9,1]`:     `r tz_tibble[9,2]`
- `r tz_tibble[10,1]`:    `r tz_tibble[10,2]`
- `r tz_tibble[11,1]`:    `r tz_tibble[11,2]`

For a complete list of geographic locations, see Suppl. Table X in the appendix.

Age among all participants ranged from `r min(desctable.data$slypos_demographics_age)` years to `r max(desctable.data$slypos_demographics_age)` years [EFA: *min* = `r min(desctable.data$slypos_demographics_age[desctable.data$IncludedInCFA == "1. EFA Sample"])`, *max* = `r max(desctable.data$slypos_demographics_age[desctable.data$IncludedInCFA == "1. EFA Sample"])`; CFA: *min* = `r min(desctable.data$slypos_demographics_age[desctable.data$IncludedInCFA == "2. CFA Sample"])`, *max* = `r max(desctable.data$slypos_demographics_age[desctable.data$IncludedInCFA == "2. CFA Sample"])`], with an overall mean of \~ `r round(mean(desctable.data$slypos_demographics_age), 0)` years of age [Overall: *M* = `r mean(desctable.data$slypos_demographics_age)`, *SD* = `r sd(desctable.data$slypos_demographics_age)`; EFA: *M* = `r mean(desctable.data$slypos_demographics_age[desctable.data$IncludedInCFA == "1. EFA Sample"])`, *SD* = `r sd(desctable.data$slypos_demographics_age[desctable.data$IncludedInCFA == "1. EFA Sample"])`; CFA: *M* = `r mean(desctable.data$slypos_demographics_age[desctable.data$IncludedInCFA == "2. CFA Sample"])`, *SD* = `r sd(desctable.data$slypos_demographics_age[desctable.data$IncludedInCFA == "2. CFA Sample"])`]. In total `r desc_tibble[3,2]` of the participants indicated female sex [EFA: `r desc_tibble[3,3]`; CFA: `r desc_tibble[3,4]`], `r desc_tibble[4,2]` indicated male [EFA: `r desc_tibble[4,3]`; CFA: `r desc_tibble[4,4]`] and `r desc_tibble[5,2]` indicated other sex [EFA: `r desc_tibble[5,3]`, CFA: `r desc_tibble[5,4]`]. Overall, `r desc_tibble[6,2]` [EFA: `r desc_tibble[6,3]`; CFA: `r desc_tibble[6,4]`] participants indicated a gender-variant identity. In a "Yes/No" question regarding native language, `r desc_tibble[7,2]` of respondents [EFA: `r desc_tibble[7,3]`; CFA: `r desc_tibble[7,4]`] indicated to be native English speakers. For their "Occupational Status", more than half of the overall sample reported that they currently work [Overall: `r desc_tibble[9,2]`; EFA: `r desc_tibble[9,3]`; CFA: `r desc_tibble[9,4]`], whereas `r desc_tibble[10,2]` [EFA: `r desc_tibble[10,3]`; CFA: `r desc_tibble[10,4]`] reported that they go to school and `r desc_tibble[11,2]` [EFA: `r desc_tibble[11,3]`; CFA: `r desc_tibble[11,4]`] responded that they do "Neither". With respect to the COVID-19 pandemic we asked participants to indicate their occupational setting during the last four weeks: In the overall sample `r desc_tibble[13,2]` [EFA: `r desc_tibble[13,3]`; CFA: `r desc_tibble[13,4]`] of the participants indicated that they were in a home office/ home schooling setting, while `r desc_tibble[14,2]` overall [EFA: `r desc_tibble[14,3]` ; CFA: `r desc_tibble[14,4]`] reported face-to-face work/schooling. Lastly, `r desc_tibble[15,2]` overall [EFA: `r desc_tibble[15,3]` ; CFA: `r desc_tibble[15,4]`] reported a combination of home- and face-to-face work/schooling, whereas `r desc_tibble[16,2]` overall [EFA: `r desc_tibble[16,3]`; CFA: `r desc_tibble[16,4]`] filled in the "Neither (no work or school, or on vacation)" response option. We tested all demographic variables in Table 1 for significant group differences between the EFA and CFA sample, applying Wilcoxon rank sum test for the continuous variable "Age" and Pearson's $\chi^2$ test for all other categorical variables via the gtsummary R package's "add_p" function [@sjoberg2021] . The p-values were corrected for multiple testing applying false discovery rate (FDR) via the "add_q" function of the same package. After p-value (FDR) correction for multiple testing, none of the demographic variables were significantly different between the EFA sample and the CFA sample (all q-values *q* $\ge$ `r min(desc_tibble$"**q-value**", na.rm=T)`).


## Item Generation

To ensure construct adequacy we thoroughly assessed the current status of literature and identified a variety of light exposure related scales. However, no scales specifically measuring the behavioral component of light exposure were found (Table \@ref(tab:eltab)). Consequentially we pursued to introduce a new openly available scale to address this research gap. For this purpose an expert researcher panel from the fields of chronobiology, light research, neuroscience and psychology (including seven of the authors, see authors roles) generated and collected preliminary item ideas. Special attention was paid to design items circumscribed to assess light exposure *behavior* as opposed to subjective measurements of the light environment (cf.[@eklund1996development] & [@dianat2013objective]) and semi-quantitive assesments of light sources' illuminance (cf. [@bajaj2011validation]) in order to maintain content validity. In a collective effort the generated items were then peer-reviewed,  amended, unified, and complemented with a suitable response scale (5 point Likert-scale ranging from 1 "Never/Does not apply/I don’t know" to 5 "Always"). This process was finalized when all experts were in agreement, resulting in 48 items to implement in the data collection.

```{r Manuflowchart, include=FALSE }
Flowchart1 <- grViz("digraph my_flowchart{
         
                    graph [fontname = Helvetica,layout = dot,fontsize = 45,layout = dot ]
                     
                     node[fontname = Helvetica, shape = rectangle, margin = 0.2, width = 16, height = 2, 
                    fixedsize = true,fontsize = 45]  
                     
                    A[label = '48 items were generated'] 
                    B[label = 'Exploratory Factor Analysis on 48 Items (n = 428)']
                    
                    node[fontname = Helvetica, shape = rectangle, margin = 0.2, width = 16, height = 6, 
                    fixedsize = true, fontsize = 45]
                    C[label = 
                    <Factor Identification<br/>Scree Plot: 6 Factors<br/>Parallel Analysis: 6 Factors<br/>Minimum Average Partial Method: 5 Factors<br/>Hull Method: 5 Factors>
                    ]
                    
                     subgraph cluster_1 {
                      graph[fontname = Helvetica, shape = box, style =dashed]
                      
                     node[fontname = Helvetica, margin = 0.2,width = 22, height = 2.5, 
                    fixedsize = true, fontsize = 45,style =dashed]
                    
                     1[label = '5 Factor Solution Retained 25 Items']
                     2[label = <Reliability Analysis on EFA Sample (n=428)<br/>Ordinal alpha F1 =.94; F2 = .76; F3 = .75; F4 =.72; F5 =.62.>]
                    
                     3[label = <Confirmatory Factor Analysis<br/>on the Five Factor Model (25 Items; n=262)<br/>Acceptable Fit ( CFI = .94; TLI .93; RMSEA = .06, SRMR = .11)>]
                    
                    4[label = <Confirmatory Factor Analysis<br/>on the Five Factor Model (23 Items; n=262)<br/>Acceptable Fit ( CFI = .97; TLI= .96; RMSEA = .04, SRMR = .09)>]
                     5[label = <Reliability Analysis (23 Items; n=262)<br/>Ordinal alpha F1=.93; F2=.83; F3 =.70; F4=.69; F5=.52<br/>Mcdonald  omega(total) for the total scale = .73>]
                    8[label = <Measurement Invariance Analysis<br/>Residual measurement invariance achieved>]
                    9[label = 'Semantic Analysis']
                    10[label = <LEBA Short Form (18 Items; n=690)<br/>Based on Item Response Theory>]
                    }
                subgraph cluster_2 {
                      graph[fontname = Helvetica,shape = rectangle]
                      style = rounded
                     node[fontname = Helvetica, margin = 0.2,width = 18, height = 2.5, 
                fixedsize = true, fontsize = 45 ]
                    6[label = 
                    <6-Factor solution:<br/>one factor emerged with only two salient loadings>
                    ]
                    7[label = 'Rejected']
                    }     
                     
                    
                     edge[fontname = Helvetica,color = black,arrowhead = vee, arrowsize = 1.25]
                     A ->B
                     B ->C
                     C ->1
                     1 ->2
                     2 ->3
                     3 ->4
                     4 ->5
                    5->8
                    8 ->9
                    9 ->10
                     C ->6
                     6 ->7
                     
                     
}")

library(jpeg)
export_svg(Flowchart1) %>%
  charToRaw() %>%
  rsvg() %>%
  png::writePNG("Manuscript.figures/Flowchart1.jpeg", dpi = 600)



```

## Analytic Strategies

Figure \@ref(fig:FlowchartFig) summarizes the steps of our psychometric analysis. In our analysis we used R (version 4.1.0), with several R packages. Initially, our tool had six point Likert type response format (0:Does not apply/I don't know; 1:Never, 2:Rarely; 3:Sometimes; 4:Often; 5:Always). Our purpose was to capture light exposure related behavior and these two response options: "Does not apply/I don't know" and "Never" were providing similar information. As such we decided to collapse them into one, making it a 5 point Likert type response format. Necessary assumptions of EFA, including sample adequacy, normality assumptions, quality of correlation matrix, were assessed. Our data violated both the univariate and multivariate normality assumptions. Due to these violations and the ordinal nature of our response data, we used  polychoric correlation matrix [@desjardinsHandbookEducationalMeasurement2018] for the EFA. We employed principal axis (PA) as  factor extraction method with varimax rotation. PA is robust to the normality assumption violations [@watkinsStepbyStepGuideExploratory2020]. The obtained latent structure was confirmed by another factor extraction method: "the minimum residuals extraction" as well. We used a combination of factor identification method including scree plot [@cattellScreeTestNumber1966], Horn's parallel analysis [@hornRationaleTestNumber1965], minimum average partials method [@velicerDeterminingNumberComponents1976], and hull method [@lorenzo-sevaHullMethodSelecting2011] to identify factor numbers. Additionally, to determine the simple structure, we followed the guidelines recommended by psychometricians: (i) no factors with fewer than three items (ii) no factors with a factor loading <0.3 (iii) no items with cross-loading greater than .3 across factors [@bandalosFactorAnalysisExploratory2018]. We confirmed the latent structure obtained in the EFA by conducting a categorical "Confirmatory Factor Analysis" (CFA) using "robust weighted least square estimator" (WLSMV). We estiablished the measurement invariance of our tool across the native and non-native English speakers using structural equation model framework. To assess the possible semantic overlap of our tool with the existing tools, we sought to "Semantic Scale Network" [@rosenbusch2020semantic].To assess the possible semantic overlap of our tool with the existing tools, we sought to "Semantic Scale Network" [@rosenbusch2020semantic].  Lastly, we sought "Item Response Theory" (IRT) based analysis on developing a short form of LEBA.
We also conducted psychometric analysis on non-merged response options data (Supp. Table \@ref(tab:efaunmerged)) and rejected the latent structure obtained as the factors were less interpretable.

```{r FlowchartFig, echo=FALSE, fig.align='center', fig.cap='Development of long and short form of LEBA', out.height='100%', out.width='100%'}
knitr::include_graphics('Manuscript.figures/Flowchart1.jpeg', dpi = 800 )
```

# Results
```{r ggplot2, include=F}
apatheme=theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        #text=element_text(family = "Helvetica"),
        axis.text.x = element_text(size = 15),
        axis.text.y = element_text(size = 15),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        plot.title = element_text(size = 15),
        legend.text = element_text(size = 15),
        legend.title=element_blank(),
        axis.line.x = element_line(color='black'),
        axis.line.y = element_line(color='black'),
        panel.border = element_rect(color = "black",
                                    fill = NA,
                                    size = 1))


```

```{r EFAdata, include=FALSE}
### EFA data
EFA.data <- sem.data[1:428, ]
#library(VIM)
missing <- VIM::aggr(EFA.data, plot =T)

```

```{r EFAassumptions, include=FALSE}

#KMO test
KMO <- psych::KMO(EFA.data) 

# Test of correlation matrix
bartlet <- psych::cortest.bartlett(EFA.data, n =428)


#Histogram
psych::multi.hist(EFA.data[,sapply(EFA.data, is.numeric)])

# Univariate normality

#creating normality function
shapiro_test_df <- function(df, bonf= TRUE, alpha= 0.05) {
  l <- lapply(df, shapiro.test)
  s <- do.call("c", lapply(l, "[[", 1))
  p <- do.call("c", lapply(l, "[[", 2))
  if (bonf == TRUE) {
    sig <- ifelse(p > alpha / length(l), "H0", "*")
  } else {
    sig <- ifelse(p > alpha, "H0", "*")
  }
  return(list(statistic= s,
              p.value= p,
              significance= sig,
              method= ifelse(bonf == TRUE, "Shapiro-Wilks test with Bonferroni Correction",
                             "Shapiro-Wilks test without Bonferroni Correction")))
}


Shapiro.efa <- shapiro_test_df(EFA.data)


efa.normality.tab = matrix(nrow = 48, ncol = 2)
rownameprefix <- "Item"
rownamesufix <- seq(1:48)
my.item.names <- paste(rownameprefix,rownamesufix, sep = "" )
rownames(efa.normality.tab) <- my.item.names
colnames(efa.normality.tab) <- c("statistic", "p")

efa.normality.tab[,1] <- apa(Shapiro.efa$statistic,2,T)
efa.normality.tab[,2] <- apa(Shapiro.efa$p.value,2,T)

efa.normalityprefix <- efa.normality.tab[,1]
efa.normalitysufix <- Shapiro.efa$significance
efa.normality.stat <- paste(efa.normalityprefix,efa.normalitysufix, sep = "" )

# Multivariate Normality
mardia <- psych::mardia(EFA.data, na.rm = T, plot =T)

# Descriptive Stats
Descriptives <- psych::describe(EFA.data)
alpha <- psych::alpha(EFA.data,check.keys=TRUE)
Item.total <- alpha$item.stats

Des.combined <- cbind(apa(Descriptives$mean,2,T), apa(Descriptives$sd,2,T), apa(Descriptives$skew,2,T),apa(Descriptives$kurtosis,2,T), efa.normality.stat,  apa(Item.total$r.cor,2,T))

colnames(Des.combined) = c("Mean", "SD", "Skew", "Kurtosis", "Shapiro-Wilk Statistics","Item-Total Correlation")
rownameprefix <- "Item"
rownamesufix <- seq(01:48)
my.names <- paste(rownameprefix,rownamesufix, sep = "" )
rownames(Des.combined) = (my.names)
rownames(Des.combined)[rownames(Des.combined) == "Item1"] <- "Item01"
rownames(Des.combined)[rownames(Des.combined) == "Item2"] <- "Item02"
rownames(Des.combined)[rownames(Des.combined) == "Item3"] <- "Item03"
rownames(Des.combined)[rownames(Des.combined) == "Item4"] <- "Item04"
rownames(Des.combined)[rownames(Des.combined) == "Item5"] <- "Item05"
rownames(Des.combined)[rownames(Des.combined) == "Item6"] <- "Item06"
rownames(Des.combined)[rownames(Des.combined) == "Item7"] <- "Item07"
rownames(Des.combined)[rownames(Des.combined) == "Item8"] <- "Item08"
rownames(Des.combined)[rownames(Des.combined) == "Item9"] <- "Item09"
```

## Item Analysis

```{r ItemAnalysis, include=FALSE}
# Item analysis
Item_analysis <- psych::alpha(EFA.data,check.keys=TRUE)
Item_analysis$item.stats$r.cor
low.r.corec <- (min(Item_analysis$item.stats$r.cor))  #minimum item total correlation
high.r.corec <- (max(Item_analysis$item.stats$r.cor))     # maximum item total correlation
```

Table \@ref(tab:tabDes) summarizes the univariate descriptive statistics for the 48 items. Some of the items were skewed with high Kurtosis values. Our data violated both univariate normality (Shapiro-Wilk statistics; [@shapiroAnalysisVarianceTest1965]) and multivariate normality assumptions [Marida's test;[@mardiaMeasuresMultivariateSkewness1970]]. Multivariate skew was = `r printnum(mardia$b1p)` (p <0.001) and multivariate kurtosis was = `r printnum(mardia$b2p)` (p <0.001). Due to these violations and ordinal nature of the response data polychoric correlations over Pearson's correlations was chosen [@desjardinsHandbookEducationalMeasurement2018]. The corrected item-total correlation ranges between `r apa(low.r.corec,2,F)` -`r apa(high.r.corec,2,F)`. However, no item was discarded based on descriptive statistics or item analysis.

## Exploratory Factor Analysis
```{r CorrMatrix, include=FALSE}
#Polychoric Correlation matrix

correlations <- psych::polychoric(EFA.data, correct = 0)
upper <- correlations$rho[upper.tri(correlations$rho, diag = F)]

min.cor <- apa(min(abs(upper)),2,F) #minimum cor.coefficient of the matrix
max.cor <- apa(max(abs(upper)),2,F) # max. correlation coefficient of the matrix

determinets <- det(correlations$rho) 
# Calculating the percentage of correlations higher than .30

BigR = sum(correlations$rho >= abs(.30) & correlations$rho < abs(1.0), na.rm =T)/2 
totR = length(EFA.data)*(length(EFA.data)-1)/2
cor.per <- print (BigR/totR)*100
```

Sampling adequacy was checked using Kaiser-Meyer-Olkin (KMO) measures of sampling adequacy [@kaiserIndexFactorialSimplicity1974] . The overall KMO vale for 48 items was `r printnum(KMO$MSA)` which was above the cutoff value (.50) indicating a mediocre sample [@hutchesonMultivariateSocialScientist1999].  Bartlett's test of sphericity [@bartlettNoteMultiplyingFactors1954], $\chi^2$ (`r bartlet$df`) = `r apa(bartlet$chisq, 2, T)`, p < .001 indicated the correlations between items are adequate for the EFA. However only `r apa(cor.per, 2,T)`% of the inter-item correlation coefficients were greater than .30. The absolute value of inter-item correlation ranged between `r min.cor` to `r max.cor`. Figure \@ref(fig:figCor) depicts the correlation matrix.
```{r tabDes,results='asis'}
apa_table(Des.combined, caption = "Descriptive Statistics", align = "c", note = "*p<.001", longtable =T)
```

```{r}
corplot <- ggcorrplot(correlations$rho, hc.order = TRUE, outline.col = "white", type = "lower", 
           ggtheme = ggplot2::theme_minimal(),,tl.srt = 90,colors = c("red", "white", "blue") )+
  theme( panel.grid.major = element_blank(),
         axis.text.x = element_text(size = 8),
         axis.text.y = element_text(size = 8),
         panel.border = element_rect(color = "black",
                                    fill = NA,
                                    size = 1))
#p.mat <- cor_to_p(correlations$rho, 428, method = "polychoric")
#to show pvalue in the fig add p.mat=p.mat
ggsave("Manuscript.figures/corplot.png",corplot, width = 6, height = 6, dpi = 600, bg ="white")

```


```{r figCor, out.height="150%",out.width="100%",fig.cap= "Inter item ploychroric correlationc coefficients for the 48 items. The red gradient indicates negative correlations, white indicates zero correlation and the blue gradient indicate positive correlations. 4.9% inter-item correlation coefficients were higher than .30 ",results='asis', fig.align='center'}

knitr::include_graphics('Manuscript.figures/corplot.png', dpi =600)

```

```{r ParallelEFA, include=FALSE}

# Parallel analysis
Horn <- paran(correlations$rho, iterations=500, centile=0, quietly=FALSE,
           status=TRUE, all=FALSE, cfa=FALSE, graph=TRUE,
           color=TRUE, col=c("black","red","blue"),
           lty=c(1,2,3), lwd=1, legend=TRUE, 
           width=640, height=640, grdevice=png, seed=0, mat=NA, n=NA)


Adjusted.EV <- data.frame(Horn$AdjEv)
Adjusted.EV$type = c('Adjusted Ev')
Adjusted.EV$num = c(row.names(Adjusted.EV))
Adjusted.EV$num = as.numeric(Adjusted.EV$num)
colnames(Adjusted.EV) = c('eigenvalue', 'type', 'num')


Random.EV <- data.frame(Horn$RndEv)
Random.EV$type = c('Random EV')
Random.EV$num = c(row.names(Random.EV))
Random.EV$num = as.numeric(Random.EV$num)
colnames(Random.EV) = c('eigenvalue', 'type', 'num')


Unadjusted.EV <- data.frame(Horn$Ev)
Unadjusted.EV$type = c('Unadjusted EV')
Unadjusted.EV$num = c(row.names(Unadjusted.EV))
Unadjusted.EV$num = as.numeric(Unadjusted.EV$num)
colnames(Unadjusted.EV) = c('eigenvalue', 'type', 'num')



parallel = ggplot(Adjusted.EV, aes(x=num, y=eigenvalue, shape=type, color=type)) +
  #Add lines connecting data points
  geom_line(colour ='black')+
    #geom_line(data = Random.EV) +
  #geom_line(data = Unadjusted.EV)+
    #Add the data points.
  geom_point(size=2,colour ='black')+
  #geom_point(data = Random.EV, size=3)+
  #geom_point(data = Unadjusted.EV, size=3)+
  scale_y_continuous(name="Eigen Value", limits=c(0, 7), breaks=seq(0,7,1)) +
   #Label the x-axis 'Factor Number', and ensure that it ranges from 1-max # of factors, increasing by one with each 'tick' mark.
  scale_x_continuous(name='Factor Number (Parallel Analysis)', limits=c(0, 48),breaks=seq(0,48,4))+
    #Add vertical line indicating parallel analysis suggested max # of factors to retain
  geom_hline(yintercept=1, linetype = 'dashed') + apatheme +theme(,legend.position = "None") 
#text = element_text(size = 25)

```

```{r ScreePlot, include=FALSE}
Scree <- scree(correlations$rho,factors=TRUE,pc=TRUE,main="(B)",
      hline=NULL,add=F)


FA.Scree <- data.frame(Scree$fv)
FA.Scree$type = c('Factor Analysis')
FA.Scree$num = c(row.names(FA.Scree))
FA.Scree$num = as.numeric(FA.Scree$num)
colnames(FA.Scree) = c('eigenvalue', 'type', 'num')

PA.Scree <- data.frame(Scree$pcv)
PA.Scree$type = c('Principal Component Analysis')
PA.Scree$num = c(row.names(PA.Scree))
PA.Scree$num = as.numeric(PA.Scree$num)
colnames(PA.Scree) = c('eigenvalue', 'type', 'num')


scree.plot <-ggplot(FA.Scree, aes(x=num, y=eigenvalue,color=type, shape=type))+
   geom_line(colour ='black')+
  #geom_line(data = PA.Scree)+ 
  geom_point(size=2,colour ='black')+
  #geom_point(data = PA.Scree, size=3)+
  scale_y_continuous(name="Eigen Value", limits=c(0, 7), breaks=seq(0,7,1)) +
  scale_x_continuous(name='Factor Number (Scree Plot)', limits=c(0, 20),breaks=seq(0,20,4))+
  geom_hline(yintercept=1, linetype = 'dashed') + apatheme +theme(legend.position = "None") 
#text = element_text(size = 25

```

```{r HullEFA, include=FALSE}
# HULL
EFA.MRFA::hullEFA(EFA.data,extr = "ULS", index_hull = "CAF", display = TRUE, graph = T,
        details = TRUE)
hull <- ggplot2::last_plot()
Hull <- hull+ ggtitle(NULL)+xlab("Factor Number (Hull Method)")+ylab("CAF")+ aes(color = "black")+
  apatheme +scale_color_manual(labels = c("Out side the convex Hull", "On the convex Hull"), values = c("black", "black"))+theme(legend.position = "None") 


```

```{r MAPefa, include=FALSE}
#MAP
map <- psych::VSS(EFA.data, rotate = "varimax", fm = 'minres', n.obs =428 )
map.map <- as.data.frame(map$map)
colnames(map.map) <- "MAP Statistic"
map.statistics <- map$vss.stats[,c(1,2,5,6,7,10,11)]
full.map <- cbind(map.map,map.statistics)

write.csv(full.map, "Table_raw/map_stat")
```
Scree plot ( Figure \@ref(fig:facIdFig)) suggested a six-factor solution. Horn's parallel analysis [@hornRationaleTestNumber1965] with 500 iterations also indicated a six-factor solution. However, the minimum average partial (MAP) method (Table \@ref(tab:factormp)) [@velicerDeterminingNumberComponents1976] and Hull method [@lorenzo-sevaHullMethodSelecting2011] ( Figure \@ref(fig:facIdFig)) suggested a five-factor solution. As a result, we tested both five-factor and six-factor solutions.
```{r factors, include=F}
fator <- cowplot::plot_grid(parallel, scree.plot,Hull, 
                   labels = "AUTO",
                   ncol=1, 
                  align = "v", 
                  label_fontfamily = "Arial",
                  label_fontface = "plain")
ggsave("Manuscript.figures/factors.png",fator, width = 6, height = 12, dpi = 600)
```

```{r facIdFig, out.height="100%", out.width="100%",fig.align='center', fig.cap='Factor Identification Methods (A) In parallel analysis we drew 500 sets of random data with the same number of participants as our orihinal data (n=428) and adjusted the mean eigenvalues for sample bias. In x-axis we plotted the number of possible factors and in y axis we plotted the mean ajusted eigenvalues. The First inflection point of the plot indicated the optimal number of factor was six. re  (B) In the scree scree plot possible numner of factors are plotted againest obtained eigen values. Scree plot suggested six factors. (C) In Hull method we plotted the number of posible factors in the x axis and in the y axis we ploed the CAF index(CAF: Common Part Accounted for-an indicator of model fit). Hull method indicated 5 factors are requied to  balance model fit and the number of parameters ',  warning=FALSE, results= 'asis'}

knitr::include_graphics('Manuscript.figures/factors.png', dpi =800)

```

```{r EFA, include=FALSE}
fa.5F.1 <- fa(r=correlations$rho, nfactors = 5, fm= "pa",rotate ="varimax",
              residuals = TRUE, SMC = TRUE, n.obs =428)
AA <- print(fa.5F.1, cut = .3, digits = 3, sort = TRUE)


reduced.model.5F.1 <- dplyr::select(EFA.data ,
                                    -c( item20, item19, item05, item31, item44, item24, item43, item39, item22, item02, item18, item48, item42, item29, item06, item15, item23, item28, item14))

correlations.red.5F.1 <- polychoric(reduced.model.5F.1,correct = 0)

fa.5F.2 <- fa(r=correlations.red.5F.1$rho, nfactors = 5, fm= "pa",rotate ="varimax",
              residuals = TRUE, SMC = TRUE, n.obs =428)

BB <- print(fa.5F.2, cut = .3, digits = 3, sort = TRUE)

reduced.model.5F.2 <- dplyr::select(EFA.data, -c( item20, item19, item05, item31, item44, item24, item43, item39, item22, item02, item18, item48, item42, item29, item06, item15, item23, item28, item14, item34, item47, item21, item13))

correlations.red.5F.2 <- polychoric(reduced.model.5F.2,correct = 0)


fa.5F.3 <- fa(r=correlations.red.5F.2$rho, nfactors = 5, fm= "pa",rotate ="varimax",
              residuals = TRUE, SMC = TRUE, n.obs =428,max.iter = 500 )

CC <- print(fa.5F.3, cut = .3, digits = 3, sort = TRUE)

var1 <- CC$Vaccounted[2,1]*100
var2 <- CC$Vaccounted[2,2]*100
var3 <- CC$Vaccounted[2,3]*100
var4 <- CC$Vaccounted[2,4]*100
var5 <- CC$Vaccounted[2,5]*100
```

```{r EFAplotcode, include=FALSE}

EFAplot <- grViz("
digraph nicegraph {

graph [layout = dot,rankdir = LR, fontsize = 40]

# node definitions with substituted label text
node [fontname = Helvetica, shape = circle,  margin = 0.5, width = 3.5, height = .5,
fixedsize = true, fontsize = 40]
F5 [label = 'F5']
F4 [label = 'F4']
F3 [label = 'F3']
F2 [label = 'F2']
F1 [label = 'F1']

node [fontname = Helvetica, shape = box, fontsize = 50, height = 1]
b [label = 'item16']
c [label = 'item36']
d [label = 'item17']
e [label = 'item11']
f [label = 'item10']
g [label = 'item12']
h [label = 'item7']
i [label = 'item8']
j [label = 'item9']
k [label = 'item27']
l [label = 'item3']
m [label = 'item40']
n [label = 'item30']
o [label = 'item41']
p [label = 'item33']
q [label = 'item32']
r [label = 'item35']
s [label = 'item37']
t [label = 'item38']
u [label = 'item46']
v [label = 'item45']
w [label = 'item25']
x [label = 'item4']
y [label = 'item1']
z [label = 'item26']


# edge definitions with the node IDs
edge [fontname = Helvetica, fontsize = 40]
F5 -> u [label = '0.60']
F5 -> v [label = '0.59']
F5 -> w [label = '0.41']
F5 -> x [label = '0.41']
F5 -> y [label = '0.40']
F5 -> z [label = '0.35']
F4 -> p [label = '0.74']
F4 -> q [label = '0.73']
F4 -> r [label = '0.66']
F4 -> s [label = '-0.39', color =red]
F4 -> t [label = '0.39']
F3 -> k [label = '0.80']
F3 -> l [label = '0.80']
F3 -> m [label = '0.65']
F3 -> n [label = '0.49']
F3 -> o [label = '36']
F2 -> e [label = '0.79']
F2 -> f[label = '0.76']
F2 -> g [label = '0.65']
F2 -> h[ label = '0.50']
F2 -> i [label = '-.49',color =red]
F2 -> j [label = '0.32']
F1 -> b[label = '0.99']
F1-> c [label = '0.93']
F1-> d [label = '0.80']
}
")


export_svg(EFAplot) %>%
  charToRaw() %>%
  rsvg() %>%
  png::writePNG("Manuscript.figures/EFAplot.png",dpi =600)

```

```{r Cronbach alpha for 5 fators, message=TRUE, warning=FALSE, include=FALSE}

Five.F1 <- dplyr::select(EFA.data, item16, item36, item17)
Five.F2 <- dplyr::select(EFA.data, item11, item10, item12, item07, item08, item09) 
Five.F3 <-  dplyr::select(EFA.data, item27, item03,item40, item30, item41)
Five.F4 <-  dplyr::select(EFA.data, item33,item32,item35, item37, item38)
Five.F5 <- dplyr::select(EFA.data, item46, item45, item25, item04, item01, item26)

#ordinal alpha
Five.F1.alpha <- psych::alpha(polychoric(Five.F1)$rho,check.keys=TRUE)
Five.F2.alpha <- psych::alpha(polychoric(Five.F2)$rho,check.keys=TRUE)
Five.F3.alpha <- psych::alpha(polychoric(Five.F3)$rho,check.keys=TRUE)
Five.F4.alpha <- psych::alpha(polychoric(Five.F4)$rho,check.keys=TRUE)
Five.F5.alpha <- psych::alpha(polychoric(Five.F5)$rho,check.keys=TRUE)

F1.alpha <- Five.F1.alpha$total$raw_alpha
F2.alpha <- Five.F2.alpha$total$raw_alpha
F3.alpha <- Five.F3.alpha$total$raw_alpha
F4.alpha <- Five.F4.alpha$total$raw_alpha
F5.alpha <- Five.F5.alpha$total$raw_alpha


alpha.tab <- rbind(F1.alpha,F2.alpha,F3.alpha,F4.alpha,F5.alpha )


```

```{r tabledown, include=F}
efa.table <- tabledown::fac.tab(fa.5F.3,cut=.3, complexity = F)

#Communality
Fac.5 <- fa.5F.3
min.com <- min(Fac.5$communality)
max.com <- max(Fac.5$communality)

# loading
min.loadings <- abs(min(Fac.5$loadings))
max.loadings <- abs(max(Fac.5$loadings))

# Residuals
residual.5F =residuals(fa.5F.3, diag = FALSE, na.rm =T)
#Count of numbers of residuals>.05
BigRR= sum(residual.5F>abs(.05), na.rm =T)
print(BigRR)

#Total number of off diagonal elements in the data matrix
totRR = length(reduced.model.5F.2)*(length(reduced.model.5F.2)-1)/2

# Proportion of off-diagonal elements >.05
sumR <- sum(BigRR/totRR*100)


```

With the initial 48 items we conducted three rounds of EFA and gradually discarded problematic items. (cross-loading items and poor factor loading (<.30) items). Finally, a five-factor EFA solution with 25 items was accepted with low RMSR = 0.08 [@brownConfirmatoryFactorAnalysis2015], all factor-loading higher than .30 and no cross-loading greater than .30. We further confirmed this five-factor latent structure by another EFA using varimax rotation with a minimum residual extraction method (Sup.Table \@ref(tab:MinResTab)). Table \@ref(tab:EFATable) displays the factor-loading (structural coefficients) and communality of the items. The absolute value of the factor-loading ranged from `r apa(min.loadings,2,F)` to `r apa(max.loadings, 2, F)` indicating strong coefficients. The commonalities ranged between `r apa(min.com,2,F)` to `r apa(max.com, 2, F)`. Figure \@ref(fig:EFAplot)(A) depicts the obtained five factor structure. However, the histogram of the absolute values of non-redundant residual-correlations (Figure \@ref(fig:EFAplot)(B)) showed `r apa(sumR,0, T)`% correlations were greater than the absolute value of .05, indicating a possible under-factoring. [@desjardinsHandbookEducationalMeasurement2018]. Subsequently, we fitted a six-factor solution. However, a factor emerged with only two salient variables, thus disqualifying the six-factor solution (Sup.Table \@ref(tab:sixFacTab)).
Internal consistency reliability coefficient Cronbach's alpha assumes all the factor-loadings of the items under a factor are equal [@graham2006congeneric; @novick1967coefficient] which is not the case in our sample. Additionally Cronbach's alpha coefficient has a tendency to deflate the estimates for  Likert type data as the calculation is based on pearson-correlation matrix which requires that response data should be in continuous of nature [@gadermann2012estimating; @zumbo2007ordinal]. Subsequently to get  better estimates of reliability we reported ordinal alpha which used polychoric-correlation matrix and assumed that the responses data were ordered in nature instead of continuous [@zumbo2007ordinal]. Ordinal alpha coefficient value ranges from 0 to 1 and higher value represents better reliability. In the five-factor solution, the first factor contained three items and explained `r apa(var1,2,F)`% of the total variance with a  internal reliability coefficient ordinal $\alpha$ = `r apa(F1.alpha,2,F)`. All the items in this factor stemmed from the individual's preference to use blue light filters in different light environments. The second factor contained six items and explained `r apa(var2,2,F)`% of the total variance with a  internal reliability coefficient ordinal $\alpha$ = `r apa(F2.alpha,2,F)`. Items under this factor commonly investigated an individual's hours spent outdoor. The third factor contained five items and explained `r apa(var3,2,F)`% of the total variance. Items under this factor dealt with the specific behaviors pertaining to using phone and smart-watch in bed. The internal consistency reliability coefficient was, ordinal $\alpha$ = `r apa(F3.alpha,2,F)`. The fourth factor contained five items and explained `r apa(var4,2,F)`% of the total variance with an internal consistency coefficient, ordinal $\alpha$ = `r apa(F4.alpha,2,F)`. These five items investigated the behaviors related to individual's light exposure before bedtime. Lastly, the fifth factor contained six items and explained `r apa(var5,2,F)`% of the total variance. This factor  captured individual's morning and daytime light exposure related behavior.  The  internal consistency reliability was, ordinal $\alpha$ = `r apa(F5.alpha,2,F)` . It is essential to attain a balance between psychometric properties and interpretability of the common themes when exploring the latent structure. As all of the emerged factors are highly interpretable and relevant towards our aim to capture light exposure related behavior, regardless of the apparent low reliability of the fifth factor, we retain all the five-factors with 23 items for our confirmatory factor analysis (CFA). Two items showed negative factor-loading (items 44 and 21). Upon inspection, it was understood that these items are negatively correlated to the common theme, and thus in the CFA analysis, we reversed the response code for these two items. Figure \@ref(fig:gtPic) depicts the data distribution and endorsement pattern for the included items in our LEBA tool for both the EFA and CFA sample.



```{r EFATable, results='asis'}

apa_table(efa.table,align = "c", caption = "Factor loadings and communality of the retained items", note = "Only loading higher than .30 is reported", font_size = "small")
```

```{r EFARes, message=FALSE, warning=FALSE, include=F}
#hist(residual.5F,  main = NULL, xlab = "Residuals", ylim=c(0, 400))
#abline(h =51, lwd = 2, lty = 2)
#abline(v =.05,lwd = 2, lty = 2)
res.dat <- as.data.frame(unclass(residual.5F))
residual.data <- as.data.frame(gather(res.dat, Items, Residuals))

residual.plot <- ggplot(residual.data, aes(x=Residuals)) + geom_histogram(binwidth=.04, col=I("black"),fill=I("grey")) + xlim(-.2,.2)+ ylim(0,250)+apatheme +geom_vline(xintercept = .05)+theme(axis.text.x = element_text(size = 12),
        axis.text.y = element_text(size = 12))
  labs( y="Frequency")

```

```{r EFAplotprep, include=F}
library(jpeg)
library(png)
library(cowplot)

img1 <- png::readPNG("Manuscript.figures/EFAplot.png")



p1 <- ggplot2::ggplot() + ggplot2::annotation_custom(grid::rasterGrob(img1,
                                                                      width=.4,
                                                                      height=.8),
                                                     -Inf, Inf, -Inf, Inf)+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank())
        #text=element_text(family = "Helvetica"))


EFAplot.1 <- plot_grid(
 p1, residual.plot,
  labels = "AUTO",
  align="h",
  ncol = 1,
  label_size = 15,
  label_fontfamily = "Arial",
  label_fontface = "plain",
  label_y = .99,
  label_x = .02,
 rel_heights = c(1.5,1)
)

ggsave("Manuscript.figures/EFAfull.png",EFAplot.1, width = 4, height =8, dpi = 600, bg ="white")

```


```{r EFAplot, fig.align='center', fig.cap='(A) Five Factor Solution obtained in Exploratory Factor Analysis (B) Histogram of nonredundent residula correlations', warning=FALSE,  results='asis'}

knitr::include_graphics('Manuscript.figures/EFAfull.png', dpi =600)
```

```{r gtvis, include =F}
## Recoding sem.data$item8
gt.data <- sem.data
gt.data$item08 <- as.character(gt.data$item08)
gt.data$item08 <- fct_recode(gt.data$item08,
  "5" = "1",
  "4" = "2",
  "2" = "4",
  "1" = "5"
)

## Recoding gt.data$item26
gt.data$item26 <- as.character(gt.data$item26)
gt.data$item26 <- fct_recode(gt.data$item26,
  "5" = "1",
  "4" = "2",
  "2" = "4",
  "1" = "5"
)
## Recoding gt.data$item37
gt.data$item37 <- as.character(gt.data$item26)
gt.data$item37 <- fct_recode(gt.data$item26,
  "5" = "1",
  "4" = "2",
  "2" = "4",
  "1" = "5"
)




#EFA data
gt.efa.data <- gt.data[1:428, ]

gt.efa.data.table <- gt.efa.data %>% 
  dplyr::select(item16, item36, item17,
                 item11, item10,item12,item07,item08,item09,
                 item27,  item03, item40,  item30, item41,
                 item33, item32,item35, item37,item38, 
                 item46, item45, item25, item04, item01,item26)

#Creating long data
gt.efa.long <- as.data.frame(gather(gt.efa.data.table, Items, value))
gt.efa.long$value <- as.numeric(as.character(gt.efa.long$value))

#Summarizing and creating gt object
gt.efa.tab <- gt.efa.long %>% 
  group_by(Items) %>% 
  # calculate summary stats & create data for the histogram and density plot
  dplyr::summarise(
    nr = n(),
    mean = mean(value, na.rm = TRUE),
    med = median(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    hist_data = list(value),
    dens_data = list(value),
    .groups = "drop"
  ) %>% 
  gt() 


#Preparation for likert data
efa.LEBA.likert <- as.data.frame(gt.efa.data.table) 

recod_LEBA <- c( "1" = "Never", "2" = "Rarely", "3"= "Sometimes","4" = "Often",
                 "5" = "Always")
efa.LEBA.likert <-  mutate(efa.LEBA.likert, across(starts_with("item"), ~unname(recod_LEBA[.])))

efa.LEBA.Factor = as.data.frame(lapply(efa.LEBA.likert,factor,
                                   ordered = T))
#get the items name
efa.items <- names(efa.LEBA.Factor) 
#Calculate percentage
efa.percentage <- kutils::likert(efa.LEBA.Factor, vlist = efa.items ) 

efa.percentage <- efa.percentage$table %>% 
  as.data.frame(.)

#data wrangling
labels <- c("Always", "Never","Often", "Rarely", "Sometimes","Total")
as.data.frame(labels)

full.efa.percentage <- cbind(labels,efa.percentage) #tables with labels  
full.efa.percentage<- t(full.efa.percentage ) #transpose
as.data.frame(full.efa.percentage)
full.efa.percentage1 <- full.efa.percentage[-1,-6] #removing 1st row and total column
full.efa.percentage2 <- full.efa.percentage1[, c(2, 4, 5, 3,1)]# rearranging
as.data.frame(full.efa.percentage2)


colnames(full.efa.percentage2) <- c("Never","Rarely","Sometimes","Often","Always")

efa.Items <- rownames(full.efa.percentage2)
as.data.frame(efa.Items)
full.efa.percentage3 <- cbind(efa.Items,full.efa.percentage2)

full.efa.percentage3 <- full.efa.percentage3[order(efa.Items),] 
full.efa.percentage3 <- as.data.frame(full.efa.percentage3[,-1]) %>% 
  gt()


gt.efa.table <- gt.efa.tab$'_data'
gt.liket.efa <- full.efa.percentage3$"_data"


efaTable <-  cbind( gt.efa.table, gt.liket.efa)%>% 
  gt()

gt.cfa.data <- gt.data[429:690,]
gt.cfa.data.table <- gt.cfa.data %>% 
  dplyr::select(item16, item36, item17,
                 item11, item10,item12,item07,item08,item09,
                 item27,  item03, item40,  item30, item41,
                 item32,item35,item38, item33, 
                 item46, item45, item25, item04, item01 )

gt.cfa.long <- gather(gt.cfa.data.table, Items, value)
gt.cfa.long$value <- as.numeric(as.character(gt.cfa.long$value))
gt.cfa.tab <- gt.cfa.long %>% 
  group_by(Items) %>% 
# calculate summary stats & create data for the histogram and density plot
  dplyr::summarise(
    nr = n(),
    mean = mean(value, na.rm = TRUE),
    med = median(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    hist_data = list(value),
    dens_data = list(value),
    .groups = "drop"
  ) %>% 
  
  gt()

#Preparation for likert data
cfa.LEBA.likert <- as.data.frame(gt.cfa.data.table) 

recod_LEBA <- c( "1" = "Never", "2" = "Rarely", "3"= "Sometimes","4" = "Often",
                 "5" = "Always")
cfa.LEBA.likert <-  mutate(cfa.LEBA.likert, across(starts_with("item"), ~unname(recod_LEBA[.])))

cfa.LEBA.Factor = as.data.frame(lapply(cfa.LEBA.likert,factor,
                                   ordered = T))
#get the items name
cfa.items <- names(cfa.LEBA.Factor) 
#Calculate percentage
cfa.percentage <- kutils::likert(cfa.LEBA.Factor, vlist = cfa.items ) 

cfa.percentage <- cfa.percentage$table %>% 
  as.data.frame(.)

#data wrangling
labels <- c("Always", "Never","Often", "Rarely", "Sometimes","Total")
as.data.frame(labels)

full.cfa.percentage <- cbind(labels,cfa.percentage) #tables with labels  
full.cfa.percentage <- t(full.cfa.percentage ) #transpose
as.data.frame(full.cfa.percentage)
full.cfa.percentage1 <- full.cfa.percentage[-1,-6] #removing 1st row and total column
full.cfa.percentage2 <- full.cfa.percentage1[, c(2, 4, 5, 3,1)]# rearranging
as.data.frame(full.cfa.percentage2)


colnames(full.cfa.percentage2) <- c("Never","Rarely","Sometimes","Often","Always")

cfa.Items <- rownames(full.cfa.percentage2)
as.data.frame(cfa.Items)
full.cfa.percentage3 <- cbind(cfa.Items,full.cfa.percentage2)

full.cfa.percentage3 <- full.cfa.percentage3[order(cfa.Items),] 
full.cfa.percentage3 <- as.data.frame(full.cfa.percentage3[,-1]) %>% 
  gt()


gt.cfa.table <- gt.cfa.tab$'_data'
gt.liket.cfa <- full.cfa.percentage3$"_data"


cfaTable <-  cbind( gt.cfa.table, gt.liket.cfa) %>% 
  gt() 

efa.gt <- efaTable$"_data"
cfa.gt <- cfaTable$"_data"



```

```{r efagt,include=F}
efa.gt %>% 
gt() %>% 
# histogram and density plots
  gtExtras::gt_sparkline(
    hist_data,
    type = "histogram",
    line_color = "black", 
    fill_color = "grey",
    bw = 1,
    same_limit = TRUE)%>%
  gtExtras::gt_sparkline(
    dens_data,
    type = "density",
    line_color = "black", 
    fill_color = "grey",
    bw = 0.75,
    same_limit = TRUE
  )%>%
# format decimals
  fmt_number(columns = mean:sd, decimals = 1) %>%
# header
  tab_header(
    title = md("**LEBA**"),
    subtitle = md("Summary Descriptives EFA Sample (N =428)")
  ) %>% 
  tab_footnote(
    footnote = md("**Histogram**"),
    locations = cells_column_labels(columns = hist_data)
  ) %>%
  tab_footnote(
    footnote = md("**Density**"),
    locations = cells_column_labels(columns = dens_data)
  ) %>% 
#create groups of columns
tab_spanner(
  label = "Items",
  columns = Items
) %>%
  tab_spanner(
    label = "Summary Statistics",
    columns = nr:sd
  ) %>%
  tab_spanner(
    label = "Graphics",
    columns = hist_data:dens_data
  ) %>% 
  tab_spanner(
    label = "Response Pattern",
    columns = Never:Always
  ) %>%
# change column names to appear in the table
cols_label(
  Items = ("LEBA  Items"),
  nr = ("n"),
  mean = ("Mean"),
  med = ("Median "),
  sd = (("SD")),
  hist_data = "Histogram",
  dens_data = "Density"
) %>%
# set alignment as per wish
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  opt_align_table_header(align = "left") %>%
# add coloured dots and lines on the first column
  gt_plt_dot(
    mean,
    Items,
    palette = "ggthemes::fivethirtyeight") %>% 
  gtsave("Manuscript.figures/efagt.png",vwidth = 7000)

```

```{r cfagt,include=F}
cfa.gt %>% 
gt() %>% 
# histogram and density plots
  gtExtras::gt_sparkline(
    hist_data,
    type = "histogram",
    line_color = "black", 
    fill_color = "grey",
    bw = 1,
    same_limit = TRUE)%>%
  gtExtras::gt_sparkline(
    dens_data,
    type = "density",
    line_color = "black", 
    fill_color = "grey",
    bw = 0.75,
    same_limit = TRUE
  )%>%
# format decimals
  fmt_number(columns = mean:sd, decimals = 1) %>%
# header
  tab_header(
    title = md("**LEBA**"),
    subtitle = md("Summary Descriptives CFA Sample (N =262)")
  ) %>% 
  tab_footnote(
    footnote = md("**Histogram**"),
    locations = cells_column_labels(columns = hist_data)
  ) %>%
  tab_footnote(
    footnote = md("**Density**"),
    locations = cells_column_labels(columns = dens_data)
  ) %>% 
#create groups of columns
tab_spanner(
  label = "Items",
  columns = Items
) %>%
  tab_spanner(
    label = "Summary Statistics",
    columns = nr:sd
  ) %>%
  tab_spanner(
    label = "Graphics",
    columns = hist_data:dens_data
  ) %>% 
  tab_spanner(
    label = "Response Pattern",
    columns = Never:Always
  ) %>%
# change column names to appear in the table
cols_label(
  Items = ("LEBA Items"),
  nr = ("n"),
  mean = ("Mean"),
  med = ("Median "),
  sd = (("SD")),
  hist_data = "Histogram",
  dens_data = "Density"
) %>%
# set alignment as per wish
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  opt_align_table_header(align = "left") %>%
# add coloured dots and lines on the first column
  gt_plt_dot(
    mean,
    Items,
    palette = "ggthemes::fivethirtyeight") %>% 
  gtsave("Manuscript.figures/cfagt.png",vwidth = 7000)

```

```{r eval=FALSE, include=FALSE}
gt.fullTable <-  rbind( efa.gt, cfa.gt) %>% 
  gt() %>% 
# histogram and density plots
  gtExtras::gt_sparkline(
    hist_data,
    type = "histogram",
    line_color = "black", 
    fill_color = "grey",
    bw = 1,
    same_limit = TRUE)%>%
  gtExtras::gt_sparkline(
    dens_data,
    type = "density",
    line_color = "black", 
    fill_color = "grey",
    bw = 0.75,
    same_limit = TRUE
  )%>%
# format decimals
  fmt_number(columns = mean:sd, decimals = 1) %>%
# header
  tab_header(
    title = md("**LEBA**"),
    subtitle = md("Summary Descriptives of CFA and EFA Sample (N =690)")
  ) %>% 
  tab_footnote(
    footnote = md("**Histogram**"),
    locations = cells_column_labels(columns = hist_data)
  ) %>%
  tab_footnote(
    footnote = md("**Density**"),
    locations = cells_column_labels(columns = dens_data)
  ) %>% 
#create groups of columns
tab_spanner(
  label = "Items",
  columns = Items
) %>%
  tab_spanner(
    label = "Summary Statistics",
    columns = nr:sd
  ) %>%
  tab_spanner(
    label = "Graphics",
    columns = hist_data:dens_data
  ) %>% 
  tab_spanner(
    label = "Response Pattern",
    columns = Never:Always
  ) %>%
# change column names to appear in the table
cols_label(
  Items = ("LEBA  Items"),
  nr = ("n"),
  mean = ("Mean"),
  med = ("Median "),
  sd = (("SD")),
  hist_data = "Histogram",
  dens_data = "Density"
) %>%
# set alignment as per wish
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  opt_align_table_header(align = "left") %>%
# add coloured dots and lines on the first column
  gt_plt_dot(
    mean,
    Items,
    palette = "ggthemes::fivethirtyeight"
  ) %>% 
    tab_row_group(
      group = "CFA (n =262)",
     rows = 26:48
    
  ) %>% 
  tab_row_group(
  group = "EFA (n = 428)",
    rows = 1:25  
  ) %>% gtsave("Manuscript.figures/gt.png",vwidth = 7000)


```

```{r efagtPic, echo=FALSE, out.height="100%", out.width= '100%', fig.cap= ' Summary Descriptives EFA Sample'}
knitr::include_graphics('Manuscript.figures/efagt.png',dpi =600)

```

```{r cfagtPic, echo=FALSE, out.height="100%", out.width= '100%', fig.cap= ' Summary Descriptives of CFA Sample'}
knitr::include_graphics('Manuscript.figures/cfagt.png',dpi =600)

```
## Confirmatory Factor Analysis

```{r CFAdataframe, include=FALSE}

### CFA Data
CFA.data <- sem.data[429:690,]

## Recoding CFA.data$item8 into CFA.data$Ritem8
CFA.data$Ritem08 <- as.character(CFA.data$item08)
CFA.data$Ritem08 <- fct_recode(CFA.data$Ritem08,
  "5" = "1",
  "4" = "2",
  "2" = "4",
  "1" = "5"
)
CFA.data$Ritem08 <- as.numeric(as.character(CFA.data$Ritem08))

## Recoding CFA.data$item37 into CFA.data$item37_rec
CFA.data$Ritem37 <- as.character(CFA.data$item37)
CFA.data$Ritem37 <- fct_recode(CFA.data$Ritem37,
  "5" = "1",
  "4" = "2",
  "2" = "4",
  "1" = "5"
)
CFA.data$Ritem37 <- as.numeric(as.character(CFA.data$Ritem37))

## Recoding CFA.data$item26 into CFA.data$Ritem26
CFA.data$Ritem26 <- as.character(CFA.data$item26)
CFA.data$Ritem26 <- fct_recode(CFA.data$Ritem26,
  "5" = "1",
  "4" = "2",
  "2" = "4",
  "1" = "5"
)

#Hitogram
#psych::multi.hist(CFA.data[,sapply(CFA.data, is.numeric)])
```

```{r CFA25items, include=FALSE }

LB.model.Cor.1 <- "F1 =~ a1*item16 + item36 + a2*item17
                 F2 =~ item11 + item10 + item12+ item07+ Ritem08+ item09
                 F3 =~  item27+ item03+ item40 + item30 + item41
                 F4 =~ a3*item32 + item35 + item38+ a4*item33 
                 F5 =~ item46+ item45+ item25+ item04+ item01 
                       a1==a2
                       a3==a4" 


fit.Cor.1 <- cfa(LB.model.Cor.1, data = CFA.data, ordered = names(CFA.data),estimator = "WLSMV") 

## Summary of Model 
cfa.sum.1 <- summary(fit.Cor.1, fit.measures =TRUE,standardized = TRUE,rsq =TRUE)


## Selected Fit measures 
fit.1 <- fitmeasures (fit.Cor.1,c("gfi", "agfi", "nfi","rfi", 
                       "cfi.scaled","tli.scaled",
                       "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled","srmr"))


reliability1 <- semTools::reliability(fit.Cor.1)

```

```{r mod1, include=FALSE}
modfit.Cor.one <- modindices(fit.Cor.1, sort. = TRUE) 
modfit.Cor.one[modfit.Cor.one$mi>3.84,]
```

```{r CFA23withMI, include=FALSE}
LB.model.Cor.2 <- "F1 =~ a1*item16 + item36 + a2*item17
                 F2 =~ item11 + item10 + item12+ item07+ Ritem08+ item09
                 F3 =~  item27+ item03+ item40 + item30 + item41
                 F4 =~ a3*item32 + item35 + item38+ a4*item33 
                 F5 =~ item46+ item45+ item25+ item04+ item01 
                       a1==a2
                       a3==a4
                item30 ~~  item41
                     F1 ~~ 0*F2
F1 ~~ 0*F3
F1 ~~ 0*F4
F1 ~~ 0*F5
F2 ~~ 0*F3
F2 ~~ 0*F4
F2 ~~ 0*F5
F3 ~~ 0*F4
F3 ~~ 0*F5
F4 ~~ 0*F5"  

#item26 & 37 are removed
                
## Fit the model 
fit.Cor.2 <- cfa(LB.model.Cor.2, data = CFA.data, ordered = names(CFA.data),estimator = "WLSMV") 

rel.k <- semTools::reliability(fit.Cor.2, return.total = T)
## Summary of Model 
cfa.sum.2 <- summary(fit.Cor.2, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)



## Selected Fit measures 
fit.2 <- fitmeasures (fit.Cor.2,c("gfi", "agfi", "nfi","rfi", 
                       "cfi.scaled","tli.scaled",
                       "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled","srmr"))



```

```{r mod2, include=FALSE}
modfit.Cor.one <- modindices(fit.Cor.2, sort. = TRUE) 
modfit.Cor.one[modfit.Cor.one$mi>3.84,]
```

We conducted categorical confirmatory factor analysis with robust weighted least square (WLSMV) estimator since our response data was of ordinary nature [@desjardinsHandbookEducationalMeasurement2018]. Several indices are suggested to measure model fit which can be categorized as absolute, comparative and parsimony fit indices [@brownConfirmatoryFactorAnalysis2015]. Absolute fit assess the model fit at an absolute level using indices including $\chi^2$ test statistics and the standardized root mean square (SRMR). Parsimony fit indices including the root mean square error of approximation (RMSEA) considers the number of free parameters in the model to assesses the parsimony of the model. Comparative fit indices evaluate the fit of the specified model solution in relation to a more restricted baseline model restricting all covariances among the indicators as zero. Comparative fit index (CFI) and the Tucker Lewis index (TLI) are such two comparative fit indices. Commonly used Model fit guidelines [@huCutoffCriteriaFit1999; @schumacker2004beginner] includes (i) Reporting of $\chi^2$ test statistics (A non-significant test statistics is required to reflect model fit) (ii) CFI and TLI (CFI/TLI close to .95 or above/ranging between 90-95 and above) (iii) RMSEA (close to .06 or below), (iv) SRMR (close to .08 or below) to estimate the model fit. Table \@ref(tab:tabCfa) summarizes the fit indices of our fitted model. Our fitted model failed to attain an absolute fit estimated by the $\chi^2$ test. However, the $\chi^2$ test is sensitive to sample size and not recommended to be used as the sole index of absolute model fit [@brownConfirmatoryFactorAnalysis2015]. Another absolute fit index we obtained in our analysis was SRMR which does not work well with categorical data [@RN1272]. We judged the model fit based on the comparative fit indices: CFI, TLI and parsimony fit index:RMSEA. Our fitted model attained acceptable fit (CFI =`r apa(fit.1[5],2,F)`; TLI = `r apa(fit.1[6],2,F)`); RMSEA = `r apa(fit.1[7],2,F)`,[`r apa(fit.1[8],2,F)`-`r apa(fit.1[9],2,F)`, 90% CI]) with two imposed equity constrain on item pairs 32-33 [`r Hmisc::label(sem.data$item32)`;`r Hmisc::label(sem.data$item33)`] and 16-17 [`r Hmisc::label(sem.data$item16)`;`r Hmisc::label(sem.data$item17)`]. Items pair 32-33 stemed from the preference of dimming electric device's brightness before bed time and items pair 16 and 19 stemed from the preference of using blue filtering or colored glasses during the daytime. Nevertheless, SRMR value was higher than the guideline (SRMR = `r apa(fit.1[10],2,F)`). Further by allowing one pair of items (30-41) [`r Hmisc::label(sem.data$item30)`;`r Hmisc::label(sem.data$item41)`] to covary their error variance and discarding two item (item 37 & 26) for very low r-square value, our model attained best fit (CFI =`r apa(fit.2[5],2,F)`; TLI = `r apa(fit.2[6],2,F)`); RMSEA = `r apa(fit.2[7],2,F)`[`r apa(fit.2[8],2,F)`-`r apa(fit.2[9],2,F)`, 90% CI]) and SRMR value (SRMR = `r apa(fit.2[10],2,F)`) was also close to the suggestions of @huCutoffCriteriaFit1999. Internal consistency ordinal $\alpha$ for the five factors of LEBA were `r apa(rel.k[2,1],2,F)`, `r apa(rel.k[2,2],2,F)`, `r apa(rel.k[2,3],2,F)`, `r apa(rel.k[2,4],2,F)`, `r apa(rel.k[2,5],2,F)` respectively. We also estimated the internal consistency reliability of the total scale using Mcdonald's $\omega_t$  coefficient which is a better reliability estimate for multidimensional constructs [@dunn2014alpha; @sijtsma2009use]. McDonald's $\omega_t$ coefficient for the total scale was `r apa(rel.k[5,6],2,F)`. Figure \@ref(fig:figcfa) depicts the obtained CFA structure.

```{r cfaMat, results='asis'}
CFa.matrix <- matrix("NA", nrow =2, ncol = 9)
colnames(CFa.matrix) = c("Model", "Chi-Squre", "df", "CFI", "TLI", "RMSEA", "RMSEA 90% Lower CI", "RMSEA 90% Upper CI", "SRMR")
CFa.matrix[1,] = c("Five factor model:25", 
                   apa(cfa.sum.1$FIT[6],2,T), 
                   apa(cfa.sum.1$FIT[7],2,T), 
                   apa(cfa.sum.1$FIT[19],2,F), 
                   apa(cfa.sum.1$FIT[20],2,T),
                   apa(cfa.sum.1$FIT[27],2,T),
                   apa(cfa.sum.1$FIT[28],2,T),
                   apa(cfa.sum.1$FIT[29],2,T),
                   apa(cfa.sum.1$FIT[35],2,T))


CFa.matrix[2,] = c("Five factor model:23", 
                   apa(cfa.sum.2$FIT[6],2,T), 
                   apa(cfa.sum.2$FIT[7],2,T), 
                   apa(cfa.sum.2$FIT[19],2,F), 
                   apa(cfa.sum.2$FIT[20],2,T),
                   apa(cfa.sum.2$FIT[27],2,T),
                   apa(cfa.sum.2$FIT[28],2,T),
                   apa(cfa.sum.2$FIT[29],2,T),
                   apa(cfa.sum.2$FIT[35],2,T))
```

```{r tabCfa, results='asis'}
apa_table(CFa.matrix, caption = "Fit indices of CFA", align = "c", landscape = T, note = "df: Degrees of Freedom; CFI: Comparative Fit Index; TLI: Tucker Lewis Index;RMSEA:Root Mean Square Error of Approximation; CI: Confidence Interval; SRMR: Standardized Root Mean Square ")
```

```{r simulation, eval=FALSE, include=FALSE}
library("simsem")
pop.model <- "F1 =~ a1*item16 + .95*item36 + a2*item17
                 F2 =~ .87*item11 + .85*item10 + .74*item12+ .60*item07+ .50*Ritem08+ .49*item09
                 F3 =~  .78*item27+ .77*item03+ .68*item40 + .13*item30 + .20*item41
                 F4 =~ a3*item32 + .63*item35 + .33*item38+ a4*item33 
                 F5 =~ .80*item46+ .53*item45+ .36*item25+ .30*item04+ .22*item01 
                       a1==a2
                       a3==a4
                item30 ~~ .82*item41
F1~~1*F1
F2~~1*F2
F3~~1*F3
F4~~1*F4
F5~~1*F5
"  

sam.model <- "F1 =~ a1*item16 + item36 + a2*item17
                 F2 =~ item11 + item10 + item12+ item7+ Ritem8+ item9
                 F3 =~  item27+ item3+ item40 + item30 + item41
                 F4 =~ a3*item32 + item35 + item38+ a4*item33 
                 F5 =~ item46+ item45+ item25+ item4+ item1 
                       a1==a2
                       a3==a4
                item30 ~~  item41
                       "  


sim.300 <- sim(200, model = sam.model, n =200, generate = pop.model, lavaanfun = "lavaan", auto.var =T, auto.fix.first =F, seed = 123)
summary(simulation)
summaryParam(simulation, detail =T, alpha = .05)

#power should be higher than .80, average CI width should be lower than .15
#Estimate standard error bias

SD.Bias <- (summaryParam(simulation)[3]-summaryParam(simulation)[2])/summaryParam(simulation)[3]
```


```{r figcfa, fig.cap = "Five Factor  Model of LEBA obtained by Confirmatory Factor Analysis. By allowing item pain 41 and 30 to covary their error variance our model attained the best fit.", out.height="150%", out.width="100%", dpi=600,  warning=FALSE}

#library(semPlot)

semPaths (fit.Cor.2 , 
          what= "std",
          #"hide", #(hides coefficeits)
          #whatLabels = "std",
          intercepts = F,
          style ="lisrel",
          #residScale = 6,
          theme = "colorblind",
          nCharNodes = 0,
          reorder =T,
          rotation =2,
          layout ="tree",
          cardinal = T,
          curvePivot =T,
          sizeMan =6,#items length
          sizeMan2 = 2,#items
          sizeLat = 12,#factors
          thresholds = FALSE,
          equalizeManifests =F,
          fade = FALSE,
          edge.label.cex = .8,
          exoCov = T,
          centerLevels = T,
          #edge.color="black",
          label.scale=T,
          label.cex=1, #Font of factor and item name
          residuals=FALSE,
           exoVar=FALSE,
          fixedStyle=6, #Style of arrow (guide item)
          freeStyle=1#Style of arrow (other item), #XKCD = TRUE
           
          )



```

## Measurement Invariance
```{r InvarianceAnalysis_data, include=FALSE}
invariance.data <- cbind(CFA.data, data$slypos_demographics_language.factor[429:690])
colnames(invariance.data)[52] <- "English_Speaking"

mi.count <- invariance.data %>% 
  group_by(English_Speaking) %>% 
  count() %>% 
  as.data.frame()
```


Measurement invariance (MI) evaluates whether a construct has the psychometric equivalence and same meaning across groups or measurement occasions [@putnick2016measurement;@klinePrinciplesPracticeStructural2015]. We used  structural equation modeling framework to assess the measurement invariance of our developed tool across two groups: **native English speakers**(n= `r mi.count[1,2]`) and **non-native English speakers** (n = `r mi.count[2,2]`). For a detailed description these two groups please see Sup. Table \@ref(tab:midesp). Our measurement invariance testing involved successively comparing the nested models:  configural, metric, scalar, and residual invariance models with each others [@widaman1997exploring]. Among these nested models  configural model is the first and least restrictive model. The configural model assumes that the number of factors and item number under each factor will be equal across two groups. The metric invariance model assumes configural invariance of the fitted model and requires the factor-loadings of the items across the two groups to be equal. Having the factor-loadings equal across groups indicates each item contributes to the measured construct equivalently. Scalar invariance assumes the metric invariance of the fitted model demands the item intercepts to be equivalent across groups. This equity of item intercepts indicates the equivalence of response scale across the groups, i.e., persons with the same level of the underlying construct will score the same across the groups. The residual invariance model assumes metric invariance for the fitted model and adds the assumption of equality in error variances and covariances across the groups. This model is the highest level of MI and assures the equivalence of precision of items across the groups in measuring the underlying constructs. 
The invariance model fit of our tool was assessed using the fit indices including $\chi^2$ test, CFI and TLI (close to .95 or above), RMSEA (close to .06 or below) [@huCutoffCriteriaFit1999]. We excluded SRMR from our consideration as it does not behave optimally for categorical variables [@RN1272]. Table \@ref(tab:InvarianceTab) summarized the fit indices. The comparison among different measurement invariance models was made using the $\chi^2$ difference test ($\Delta \chi^2$)  to assess whether our obtained latent structure of "LEBA" attained the highest level of the MI. A non-significant $\Delta \chi^2$ test between two MI models fit indicates mode fit does not significantly decrease for the superior model [@dimitrov2010testing] thus allowing the superior level of invariance model to be accepted. We started our analysis by comparing the model fit of the least restrictive model:configural model to metric MI model and continued successive comparisons. Table \@ref(tab:InvarianceTab) indicates that our fitted model had acceptable fit indices for all of the fitted MI models. The model fit did not significantly decrease across the nested models up to the scalar MI model. The chi-square value difference between the scalar and residual model is zero, indicating model fit remained the same for both: scalar and residual MI model, indicating the acceptability of the residual MI model.


```{r Invariancedetail, include=FALSE}

LB.model.Cor.2 <- "F1 =~ a1*item16 + item36 + a2*item17
                 F2 =~ item11 + item10 + item12+ item07+ Ritem08+ item09
                 F3 =~  item27+ item03+ item40 + item30 + item41
                 F4 =~ a3*item32 + item35 + item38+ a4*item33 
                 F5 =~ item46+ item45+ item25+ item04+ item01 
                       a1==a2
                       a3==a4
                item30 ~~  item41
                       "  
# Configural invariance ####
configural <- cfa(model = LB.model.Cor.2,
                  data = invariance.data,
                  group = "English_Speaking",
                  ordered =   names(CFA.data),
                  estimator = "WLSMV")

summary(configural, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)

fitmeasures (configural,c("gfi", "agfi", "nfi","rfi", 
                       "cfi.scaled","tli.scaled",
                       "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled","srmr"))

#Metric
weak <- cfa(model = LB.model.Cor.2,
                  data = invariance.data,
                  group = "English_Speaking",
                  ordered =   names(CFA.data),
                  estimator = "WLSMV", 
            group.equal = "loadings")
            
summary(weak, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)


fitmeasures (weak,c("gfi", "agfi", "nfi","rfi", 
                       "cfi.scaled","tli.scaled",
                       "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled","srmr"))

First.comp <- compareFit (configural, weak)
summary(First.comp)



#Scaler
strong <- cfa(model = LB.model.Cor.2,
                  data = invariance.data,
                  group = "English_Speaking",
                  ordered =   names(CFA.data),
                  estimator = "WLSMV", 
              group.equal = c("loadings", "intercepts"))
summary(strong, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)

Second.comp <- compareFit  (weak, strong)
summary(Second.comp)

#residual
strict <- cfa(model = LB.model.Cor.2,
                  data = invariance.data,
                  group = "English_Speaking",
                  ordered =   names(CFA.data),
                  estimator = "WLSMV",  
              group.equal = c("loadings", "intercepts", "residuals")) 

summary(strict, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)
residual.fitm <- as.data.frame(fitmeasures (strict,c("gfi", "agfi", "nfi","rfi", "cfi","tli","rmsea", "srmr","aic")))

Third.comp <- compareFit(strict,strong)
summary(Third.comp)
#structural
structural <-cfa(model = LB.model.Cor.2,
                  data = invariance.data,
                  group = "English_Speaking",
                  ordered =   names(CFA.data),
                  estimator = "WLSMV",  
                 group.equal = c("loadings", "intercepts", "residuals", "means","lv.variances","lv.covariances"))

summary(structural, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)
fitmeasures (structural,c("gfi", "agfi", "nfi","rfi", "cfi","tli","rmsea", "srmr","aic"))

fourth.comp <- compareFit  (structural,strict)
summary(fourth.comp)
comfit.par <- compareFit(configural, weak, strong, strict)
summary (comfit.par)

models <-  list("Configural" = configural, 
                "Metric" = weak, 
                "Scalar" = strong, 
                "Residual" = strict)



Invariance.table <- compareLavaan(models,
              nesting = "Configural > Metric > Scalar > Residual", 
              fitmeas = c("chisq.scaled", "df",  "cfi.scaled","tli.scaled","rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled" ),
              scaled = T,
              chidif = T, digits = 2)

colnames(Invariance.table) <- c("Chi-Square", "df", "CFI", "TLI", "RMSEA", "RMSEA 90% Lower CI", "RMSEA 90% Upper", "Chi-Square Difference", "df difference*", "p")


```

```{r InvarianceTab, results='asis'}
apa_table(Invariance.table, align = "c",  caption = "Invariance Analysis", note = " a = Metric vs Configural; b = Scalar vs Metric; c = Residual vs Scalar; d = Structural vs Residual;* =  df of model comparison", landscape = T, font_size = "footnotesize" )

```

## Semantic Analysis 
To find out if our developed tool (23 items) is overlapping with existing instruments, we subjected the items of LEBA to the "Semantic Scale Network"(SSN) analysis [@rosenbusch2020semantic]. The SSN detects semantically related scales and provides cosine similarity index ranging between -.66 to 1 [@rosenbusch2020semantic]. Pair of scales with a cosine similarity index value of 1 indicates they are perfectly semantically similar scales indicating redundancy. LEBA  appeared most strongly related to scales about sleep: "Sleep Disturbance Scale For Children" [@bruni1996sleep] and "WHO-Composite International Diagnostic Interview (CIDI): Insomnia"[@who1990].The cosine similarities lie between .47 to .51. Flesch-Kincaid Grade Level [@flesch1948new] analysis on the the 23 items of our scale indicated required educational grade level was 3.33 and with a age above 8.33.
```{r textanalysis}
#devtools::install_github("unDocUMeantIt/koRpus")
library(koRpus)# stable release
#koRpus::install.koRpus.lang(lang=c("en"))
library(koRpus)
library(koRpus.lang.en)
ques <- tokenize("Table_raw/items.txt", 
                 format = "file",
                 fileEncoding = NULL,
                 split = "[[:space:]]",
                 ign.comp = "-",
                 heuristics = "abbr",
                 heur.fix = list(pre = c("\u2019", "'"), suf = c("\u2019", "'")),
                 abbrev = NULL,
                 tag = TRUE,
                 lang = "en",
                 sentc.end = c(".", "!", "?", ";", ":"),
                 detect = c(parag = FALSE, hline = FALSE),
                 clean.raw = NULL,
                 perl = FALSE,
                 stopwords = NULL,
                 stemmer = NULL,
                 doc_id = NA,
                 add.desc = "kRp.env")

readability <- readability(ques,
                           hyphen = NULL,
                           index = "Flesch.Kincaid",
                           parameters = list(),
                           word.lists = list(Bormuth = NULL, Dale.Chall = NULL,                              Harris.Jacobson = NULL, Spache =NULL),
                           fileEncoding = "UTF-8",
                           sentc.tag = "sentc",
                           nonword.class = "nonpunct",
                           nonword.tag = c(),
                           quiet = FALSE,
                           keep.input = NULL,
                           as.feature = FALSE)
```

## Developing Short form of LEBA
We sought the item response theory (IRT) to develop the short form of LEBA. IRT the conventional classical test theory-based analysis by gathering information on item quality by indices like item difficulty, item discrimination, and item information [@bakerBasicsItemResponse2017]. Item is  judged based on item information in relation to participants' latent trait level ($\theta$). We fitted each factor of LEBA with the graded response model [@samejima1997handbook] to the combined EFA and CFA sample (n =690). Item discrimination indicates the pattern of variation in the categorical responses with the changes in latent trait level ($\theta$), and item information curve (IIC) indicates the amount of information an item carries along the latent trait continuum. Here, we reported the item discrimination parameter and only discarded the items with relatively flat item information curve (information <.2) to develop the short form of LEBA. @bakerBasicsItemResponse2017 categorized the item discrimination in as none = 0; very low =0.01 to 0.34; low = 0.35 to 0.64; moderate = 0.65 to 1.34 ; high = 1.35 to 1.69; very high >1.70. Table \@ref(tab:IRTparameters) summarizes the IRT parameters of our tool. Item discrimination parameters of our tool fell in very high (10 items), high (4 items), moderate (4 items), and low ( 5 items) categorizes indicating a good range of discrimination along the latent trait level ($\theta$). Examination of the item information curve (Sup.fig \@ref(fig:F2IF)-\@ref(fig:F5IF)) indicated 5 items (1, 25,  38, 30, & 41) had relatively flat information curves (I($\theta$) <.20) thus discarded creating a short form of LEBA with 5 factors and 18 items.


```{r IRTdata, include=FALSE}
## Recoding sem.data$item8 into sem.data$Ritem8
sem.data$Ritem08 <- as.character(sem.data$item08)
sem.data$Ritem08 <- fct_recode(sem.data$Ritem08,
  "5" = "1",
  "4" = "2",
  "2" = "4",
  "1" = "5"
)
sem.data$Ritem08 <- as.numeric(as.character(sem.data$Ritem08))
# Recoding sem.data$item26 
sem.data$Ritem26 <- as.character(sem.data$item26)
sem.data$Ritem26 <- fct_recode(sem.data$Ritem26,
  "5" = "1",
  "4" = "2",
  "2" = "4",
  "1" = "5"
)
sem.data$Ritem26 <- as.numeric(as.character(sem.data$Ritem26))

# Recoding sem.data$item37 i
sem.data$Ritem37 <- as.character(sem.data$item37)
sem.data$Ritem37 <- fct_recode(sem.data$Ritem37,
  "5" = "1",
  "4" = "2",
  "2" = "4",
  "1" = "5"
)
sem.data$Ritem37 <- as.numeric(as.character(sem.data$Ritem37))





F1 <- sem.data %>% 
  dplyr::select(item16, item36,  item17)


F2 <- sem.data %>% 
  dplyr::select(item11,  item10 , item12, item07, Ritem08, item09)

F3 <- sem.data %>% 
 dplyr::select(item27, item03,  item40,  item30,  item41)


F4 <- sem.data %>% 
 dplyr::select(item32, item35,  item38,  item33)

F5 <- sem.data %>% 
  dplyr::select(item46, item45, item25, item04, item01 )




## F1 IRT model####
F1_fit <- mirt(F1, model = 1, itemtype = 'graded', 
               SE = TRUE, Se.type = 'MHRM',
               technical = list(NCYCLES = 10000))


## F2 IRT model####
F2_fit <- mirt(F2, model = 1, itemtype = 'graded', SE = TRUE,
               Se.type = 'MHRM',technical = list(NCYCLES = 10000))


## F3 IRT model####
F3_fit <- mirt(F3, model = 1, itemtype = 'graded', SE = TRUE,
               Se.type = 'MHRM',technical = list(NCYCLES = 10000))


## F4 IRT model####
F4_fit <- mirt(F4, model = 1, itemtype = 'graded', SE = TRUE,
               Se.type = 'MHRM',technical = list(NCYCLES = 10000))


## F5 IRT model####
F5_fit <- mirt(F5, model = 1, itemtype = 'graded', SE = TRUE,
               Se.type = 'MHRM',technical = list(NCYCLES = 10000))


# Model Parameters ####
## F1 Model Parameters####
F1_params <- coef(F1_fit, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
F1_items <- data.frame(F1_params$items)
F1l_se <- coef(F1_fit, printSE = TRUE)

## F2 Model Parameters####
F2_params <- coef(F2_fit, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
F2_items <- data.frame(F2_params$items)
F2_se <- coef(F2_fit, printSE = TRUE)

## F3 Model Parameters####
F3_params <- coef(F3_fit, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
F3_items <- data.frame(F3_params$items)
F3_se <- coef(F3_fit, printSE = TRUE)

## F4 Model Parameters####
F4_params <- coef(F4_fit, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
F4_items <- data.frame(F4_params$items)
F4_se <- coef(F4_fit, printSE = TRUE)

## F5 Model Parameters####
F5_params <- coef(F5_fit, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
F5_items <- data.frame(F5_params$items)
F5_se <- coef(F5_fit, printSE = TRUE)


itemparameters <- rbind(F1_items,F2_items, F3_items, F4_items,F5_items)


# Model Fit (degrees of freedom too low to check model fit)
#F1.model <- M2(F1_fit)
#F2.model <- M2(F2_fit)
#F3.model <- M2(F3_fit)
#F4.model <- M2(F4_fit)
#F5.model <- M2(F5_fit)


#Item fit
F1.item.fit<- itemfit(F1_fit, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)

F2.item.fit<- itemfit(F2_fit, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)
F3.item.fit<- itemfit(F3_fit, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)
F4.item.fit<- itemfit(F4_fit, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)

F5.item.fit<- itemfit(F5_fit, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)

#Identifying Missfit items based on RMSEA Value
F1.item_misfits <- subset(F1.item.fit, RMSEA.S_X2 >= .06)
F2.item_misfits <- subset(F2.item.fit, RMSEA.S_X2 >= .06)
F3.item_misfits <- subset(F3.item.fit, RMSEA.S_X2 >= .06)
F4.item_misfits <- subset(F4.item.fit, RMSEA.S_X2 >= .06)
F5.item_misfits <- subset(F5.item.fit, RMSEA.S_X2 >= .06)

# Person Fit ####
## F1 Person fit ####
F1.personfit <- personfit(F1_fit) 
F1.personfit_model_misfits <- subset(F1.personfit, Zh < -2)
rownames(F1.personfit_model_misfits)
nrow(F1.personfit_model_misfits)
hist(F1.personfit$Zh, xlab = "Zh Statistics",main = "F1 Person Fit")
abline(v = -2, lwd = 2, lty = 2)

## F2 Person fit ####
F2.personfit <- personfit(F2_fit) 
F2.personfit_model_misfits <- subset(F2.personfit, Zh < -2)
rownames(F2.personfit_model_misfits)
nrow(F2.personfit_model_misfits)
hist(F2.personfit$Zh, xlab = "Zh Statistics",main = "F1 Person Fit")
abline(v = -2, lwd = 2, lty = 2)

## F3 Person fit ####
F3.personfit <- personfit(F3_fit) 
F3.personfit_model_misfits <- subset(F3.personfit, Zh < -2)
rownames(F3.personfit_model_misfits)
nrow(F3.personfit_model_misfits)
hist(F3.personfit$Zh, xlab = "Zh Statistics",main = "F1 Person Fit")
abline(v = -2, lwd = 2, lty = 2)

## F4 Person fit ####
F4.personfit <- personfit(F4_fit) 
F4.personfit_model_misfits <- subset(F4.personfit, Zh < -2)
rownames(F4.personfit_model_misfits)
nrow(F4.personfit_model_misfits)
hist(F4.personfit$Zh, xlab = "Zh Statistics",main = "F1 Person Fit")
abline(v = -2, lwd = 2, lty = 2)


## F5 Person fit ####
F5.personfit <- personfit(F5_fit) 
F5.personfit_model_misfits <- subset(F5.personfit, Zh < -2)
rownames(F3.personfit_model_misfits)
nrow(F5.personfit_model_misfits)
hist(F5.personfit$Zh, xlab = "Zh Statistics",main = "F1 Person Fit")
abline(v = -2, lwd = 2, lty = 2)



# Plots ####
## F1 Plots ####
F1_OCC <- plot(F1_fit, type = "trace", facet =T, main = "F1: Wearing blue light filters OCC")
F1_info <- plot(F1_fit, type = "infoSE", main = "F1: Wearing blue light filters")
F1_iteminfo <- plot(F1_fit, type = "infotrace", 
                    facet_items = T, main = "F1: Wearing blue light filters")

## F2 Plots ####
F2_OCC <- plot(F2_fit, type = "trace", facet =T, main = "F2: Spending time outdoors OCC")
F2_info <- plot(F2_fit, type = "infoSE", main = "F2: Spending time outdoors")
F2_iteminfo <- plot(F2_fit, type = "infotrace", facet_items = T, main = "F2: Spending time outdoors")

## F3 Plots ####
F3_OCC <-plot(F3_fit, type = "trace", facet =T, main = "F3: Using phone and smart-watch in bed OCC")
F3_info <- plot(F3_fit, type = "infoSE", main = "F3: Using phone and smart-watch in bed")
F3_iteminfo <- plot(F3_fit, type = "infotrace", 
                    facet_items = T, main = "F3: Using phone and smart-watch in bed")

## F4 Plots ####
F4_OCC <-plot(F4_fit, type = "trace", facet =T, main = "F4: Using light before bedtime OCC")
F4_info <- plot(F4_fit, type = "infoSE", main = "F4: Using light before bedtime")
F4_iteminfo <- plot(F4_fit, type = "infotrace", facet_items = T,main = "F4: Using light before bedtime",cex = .8)


## F5 Plots ####
F5_OCC <-plot(F5_fit, type = "trace", facet =T, main = "F5: Using light in the morning and during daytime OCC")
F5_info <- plot(F5_fit, type = "infoSE", main = "F5: Using light in the morning and during daytime")
F5_iteminfo <- plot(F5_fit, type = "infotrace", facet_items = T,main = "F5: Using light in the morning and during daytime")


```

```{r IRTreliability, eval=FALSE, include=FALSE}
#conditional reliability
F1.reliability <- plot(F1_fit, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )
F2.reliability <- plot(F2_fit, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )
F3.reliability <- plot(F3_fit, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )
F4.reliability <- plot(F4_fit, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )
F5.reliability <- plot(F5_fit, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )

##IRT reliability (marginal reliability of scales)
F1.marginal.rel <- marginal_rxx(F1_fit)
F2.marginal.rel <-marginal_rxx(F2_fit)
F3.marginal.rel <-marginal_rxx(F3_fit)
F4.marginal.rel <-marginal_rxx(F4_fit)
F5.marginal.rel <-marginal_rxx(F5_fit)


##Scale characteristic curve
F1.scale <- plot(F1_fit, type = 'score', theta_lim = c(-6, 6), main = "")
F2.scale <- plot(F1_fit, type = 'score', theta_lim = c(-6, 6), main = "")
F3.scale <- plot(F1_fit, type = 'score', theta_lim = c(-6, 6), main = "")
F4.scale <- plot(F1_fit, type = 'score', theta_lim = c(-6, 6), main = "")
F5.scale <- plot(F1_fit, type = 'score', theta_lim = c(-6, 6), main = "")
```


```{r iteminfoggplot3, include=F}
Theta <- matrix(seq(-6,6, by = .1))

##Item Extraction
F1.item1 <- extract.item(F1_fit, 1)#item number
F1.item2 <- extract.item(F1_fit, 2)
F1.item3 <- extract.item(F1_fit, 3)
F2.item1 <- extract.item(F2_fit, 1)
F2.item2 <- extract.item(F2_fit, 2)
F2.item3 <- extract.item(F2_fit, 3)
F2.item4 <- extract.item(F2_fit, 4)
F2.item5 <- extract.item(F2_fit, 5)
F2.item6 <- extract.item(F2_fit, 6)
F3.item1 <- extract.item(F3_fit, 1)
F3.item2 <- extract.item(F3_fit, 2)
F3.item3 <- extract.item(F3_fit, 3)
F3.item4 <- extract.item(F3_fit, 4)
F3.item5 <- extract.item(F3_fit, 5)
F4.item1 <- extract.item(F4_fit, 1)
F4.item2 <- extract.item(F4_fit, 2)
F4.item3 <- extract.item(F4_fit, 3)
F4.item4 <- extract.item(F4_fit, 4)
F5.item1 <- extract.item(F5_fit, 1)
F5.item2 <- extract.item(F5_fit, 2)
F5.item3 <- extract.item(F5_fit, 3)
F5.item4 <- extract.item(F5_fit, 4)
F5.item5 <- extract.item(F5_fit, 5)


##Item Info
F1.item.info.1 <- iteminfo(F1.item1, Theta)
F1.item.info.2 <- iteminfo(F1.item2, Theta)
F1.item.info.3 <- iteminfo(F1.item3, Theta)
F2.item.info.1 <- iteminfo(F2.item1, Theta)
F2.item.info.2 <- iteminfo(F2.item2, Theta)
F2.item.info.3 <- iteminfo(F2.item3, Theta)
F2.item.info.4 <- iteminfo(F2.item4, Theta)
F2.item.info.5 <- iteminfo(F2.item5, Theta)
F2.item.info.6 <- iteminfo(F2.item6, Theta)
F3.item.info.1 <- iteminfo(F3.item1, Theta)
F3.item.info.2 <- iteminfo(F3.item2, Theta)
F3.item.info.3 <- iteminfo(F3.item3, Theta)
F3.item.info.4 <- iteminfo(F3.item4, Theta)
F3.item.info.5 <- iteminfo(F3.item5, Theta)
F4.item.info.1 <- iteminfo(F4.item1, Theta)
F4.item.info.2 <- iteminfo(F4.item2, Theta)
F4.item.info.3 <- iteminfo(F4.item3, Theta)
F4.item.info.4 <- iteminfo(F4.item4, Theta)
F5.item.info.1 <- iteminfo(F5.item1, Theta)
F5.item.info.2 <- iteminfo(F5.item2, Theta)
F5.item.info.3 <- iteminfo(F5.item3, Theta)
F5.item.info.4 <- iteminfo(F5.item4, Theta)
F5.item.info.5 <- iteminfo(F5.item5, Theta)


#Data frame

F1.item.info.data <- as.data.frame(cbind(Theta, F1.item.info.1, 
                                              F1.item.info.2,
                                              F1.item.info.3))

F2.item.info.data <- as.data.frame(cbind(Theta, F2.item.info.1, 
                                              F2.item.info.2,
                                              F2.item.info.3,
                                         F2.item.info.4,
                                         F2.item.info.5,
                                         F2.item.info.6))

F3.item.info.data <- as.data.frame(cbind(Theta, F3.item.info.1, 
                                              F3.item.info.2,
                                              F3.item.info.3,
                                         F3.item.info.4,
                                         F3.item.info.5))

F4.item.info.data <- as.data.frame(cbind(Theta, F4.item.info.1, 
                                              F4.item.info.2,
                                              F4.item.info.3,
                                         F4.item.info.4))
F5.item.info.data <- as.data.frame(cbind(Theta, F5.item.info.1, 
                                              F5.item.info.2,
                                              F5.item.info.3,
                                         F5.item.info.4,
                                         F5.item.info.5))

## GGplot2 item-info
###F1
F1.iteminfo.1 <- ggplot(F1.item.info.data , aes(x=Theta, y=F1.item.info.1)) +
  geom_line()  +apatheme +labs(y="Item Information", title = "F1 item16") + geom_hline(yintercept = .18, colour ="red")
F1.iteminfo.2 <- ggplot(F1.item.info.data , aes(x=Theta, y=F1.item.info.2)) +
  geom_line()  +apatheme +labs(y="Item Information", title = "F1 item36")+geom_hline(yintercept = .18, colour ="red")
F1.iteminfo.3 <- ggplot(F1.item.info.data , aes(x=Theta, y=F1.item.info.3)) +
  geom_line()  +apatheme +labs(y="Item Information", title = "F1 item17")+ylim(0,6)+geom_hline(yintercept = .18, colour ="red")

###F2

F2.iteminfo.1 <- ggplot(F2.item.info.data , aes(x=Theta, y=F2.item.info.1)) +
  geom_line()  +apatheme +labs(y="Item Information", title = "F2 item11")+ylim(0,3)+geom_hline(yintercept = .18, colour ="red")

F2.iteminfo.2 <- ggplot(F2.item.info.data , aes(x=Theta, y=F2.item.info.2)) +
  geom_line()  + apatheme +
  labs(y="Item Information", title = "F2 item10")+
  ylim(0,3)+geom_hline(yintercept = .18, colour ="red")

F2.iteminfo.3 <- ggplot(F2.item.info.data , aes(x=Theta, y=F2.item.info.3)) +
  geom_line()  +apatheme +
  labs(y="Item Information", title = "F2 item12")+
  ylim(0,3)+geom_hline(yintercept = .18, colour ="red")

F2.iteminfo.4 <- ggplot(F2.item.info.data , aes(x=Theta, y=F2.item.info.4)) +
  geom_line()  +apatheme +
  labs(y="Item Information", title = "F2 item07")+ylim(0,3)+
  geom_hline(yintercept = .18, colour ="red")

F2.iteminfo.5 <- ggplot(F2.item.info.data , aes(x=Theta, y=F2.item.info.5)) +
  geom_line()  +apatheme +
  labs(y="Item Information", title = "F2 item08")+ylim(0,3)+
  geom_hline(yintercept = .18, colour ="red")

F2.iteminfo.6 <- ggplot(F2.item.info.data , aes(x=Theta, y=F2.item.info.6)) +
  geom_line()  +apatheme +
  labs(y="Item Information", title = "F2 item09")+ylim(0,3)+
  geom_hline(yintercept = .18, colour ="red")




###F3
F3.iteminfo.1 <- ggplot(F3.item.info.data , aes(x=Theta, y=F3.item.info.1)) +
  geom_line()  +apatheme +labs(y="Item Information", title = "F3 item27")+
  ylim(0,3)+geom_hline(yintercept = .18, colour ="red")

F3.iteminfo.2 <- ggplot(F3.item.info.data , aes(x=Theta, y=F3.item.info.2)) +
  geom_line()  +apatheme +
  labs(y="Item Information",title = "F3 item03")+
  ylim(0,3)+geom_hline(yintercept = .18, colour ="red")

F3.iteminfo.3 <- ggplot(F3.item.info.data , aes(x=Theta, y=F3.item.info.3)) +
  geom_line()  +apatheme +
  labs(y="Item Information",title = "F3 item40")+
  ylim(0,3)+geom_hline(yintercept = .18, colour ="red")

F3.iteminfo.4 <- ggplot(F3.item.info.data , aes(x=Theta, y=F3.item.info.4)) +
  geom_line()  +apatheme +
  labs(y="Item Information",title = "F3 item30")+
  ylim(0,3)+geom_hline(yintercept = .18, colour ="red")

F3.iteminfo.5 <- ggplot(F3.item.info.data , aes(x=Theta, y=F3.item.info.5)) +
  geom_line()  +apatheme +
  labs(y="Item Information", title = "F3 item41")+
  ylim(0,3)+geom_hline(yintercept = .18, colour ="red")

#F4

F4.iteminfo.1 <- ggplot(F4.item.info.data , aes(x=Theta, y=F4.item.info.1)) +
  geom_line()  +apatheme +labs(y="Item Information", title = "F4 item32")+
  ylim(0,3)+geom_hline(yintercept = .18, colour ="red")

F4.iteminfo.2 <- ggplot(F4.item.info.data , aes(x=Theta, y=F4.item.info.2)) +
  geom_line()  +apatheme +
  labs(y="Item Information",title = "F4 item35")+
  ylim(0,3)+geom_hline(yintercept = .18, colour ="red")

F4.iteminfo.3 <- ggplot(F4.item.info.data , aes(x=Theta, y=F4.item.info.3)) +
  geom_line()  +apatheme +
  labs(y="Item Information",title = "F4 item38")+
  ylim(0,3)+geom_hline(yintercept = .18, colour ="red")

F4.iteminfo.4 <- ggplot(F4.item.info.data , aes(x=Theta, y=F4.item.info.4)) +
  geom_line()  +apatheme +
  labs(y="Item Information",title = "F4 item33")+geom_hline(yintercept = .18, colour ="red")


#F5

F5.iteminfo.1 <- ggplot(F3.item.info.data , aes(x=Theta, y=F5.item.info.1)) +
  geom_line()  +apatheme +labs(y="Item Information", title = "F5 item46")+
  ylim(0,2)+geom_hline(yintercept = .18, colour ="red")

F5.iteminfo.2 <- ggplot(F3.item.info.data , aes(x=Theta, y=F5.item.info.2)) +
  geom_line()  +apatheme +
  labs(y="Item Information",title = "F5 item45")+
  ylim(0,2)+geom_hline(yintercept = .18, colour ="red")

F5.iteminfo.3 <- ggplot(F3.item.info.data , aes(x=Theta, y=F5.item.info.3)) +
  geom_line()  +apatheme +
  labs(y="Item Information",title = "F5 item25")+
  ylim(0,2)+geom_hline(yintercept = .18, colour ="red")

F5.iteminfo.4 <- ggplot(F3.item.info.data , aes(x=Theta, y=F5.item.info.4)) +
  geom_line()  +apatheme +
  labs(y="Item Information",title = "F5 item04")+
 geom_hline(yintercept = .18, colour ="red")+ylim(0,2)

F5.iteminfo.5 <- ggplot(F3.item.info.data , aes(x=Theta, y=F5.item.info.5)) +
  geom_line()  +apatheme +
  labs(y="Item Information", title = "F5 item01")+
  ylim(0,2)+geom_hline(yintercept = .18, colour ="red")




#Panel plots

F1.itemplots <- cowplot::plot_grid(F1.iteminfo.1,F1.iteminfo.2, F1.iteminfo.3,
                   labels = "AUTO",
                     align="v",
                     ncol = 2,
                     label_size = 12,
                     label_fontfamily = "Arial",
  label_fontface = "plain")
ggsave("Manuscript.figures/F1.itemplots.png",F1.itemplots, width = 10, height = 12, dpi = 600,bg = "white")


F2.itemplots <- cowplot::plot_grid(F2.iteminfo.1,F2.iteminfo.2, F2.iteminfo.3,
                                   F2.iteminfo.4,F2.iteminfo.5,F2.iteminfo.6,
                   labels = "AUTO",
                     align="v",
                     ncol = 2,
                     label_size = 12,
                     label_fontfamily = "Arial",
                     label_fontface = "plain")
ggsave("Manuscript.figures/F2.itemplots.png",F2.itemplots, width = 10, height = 12, dpi = 600, bg = "white")


F3.itemplots <- cowplot::plot_grid(F3.iteminfo.1,F3.iteminfo.2, F3.iteminfo.3,
                                   F3.iteminfo.4,F3.iteminfo.5,
                 labels = "AUTO",
                     align="v",
                     ncol = 2,
                     label_size = 12,
                     label_fontfamily = "Arial",
                     label_fontface = "plain")
ggsave("Manuscript.figures/F3.itemplots.png",F3.itemplots, width = 10, height = 12, dpi = 600,bg = "white")


F4.itemplots <- cowplot::plot_grid(F4.iteminfo.1,F4.iteminfo.2, F4.iteminfo.3,
                                   F4.iteminfo.4,
                   labels = "AUTO",
                     align="v",
                     ncol = 2,
                     label_size = 12,
                     label_fontfamily = "Arial",
                     label_fontface = "plain")
ggsave("Manuscript.figures/F4.itemplots.png",F4.itemplots, width = 10, height = 12, dpi = 600,bg = "white")


F5.itemplots <- cowplot::plot_grid(F5.iteminfo.1,F5.iteminfo.2, F5.iteminfo.3,
                                   F5.iteminfo.4,F5.iteminfo.5,
                   labels = "AUTO",
                     align="v",
                     ncol = 2,
                     label_size = 12,
                     label_fontfamily = "Arial",
                     label_fontface = "plain")
ggsave("Manuscript.figures/F5.itemplots.png",F5.itemplots, width = 10, height = 12, dpi = 600, bg = "white")

```


```{r inteminfoggplo2com, eval=FALSE, include=FALSE}

pacman::p_load(reshape,ggsci)
Theta <- matrix(seq(-6,6, by = .1))

##Item Extraction
F1.item1 <- extract.item(F1_fit, 1)#item number
F1.item2 <- extract.item(F1_fit, 2)
F1.item3 <- extract.item(F1_fit, 3)
F2.item1 <- extract.item(F2_fit, 1)
F2.item2 <- extract.item(F2_fit, 2)
F2.item3 <- extract.item(F2_fit, 3)
F2.item4 <- extract.item(F2_fit, 4)
F2.item5 <- extract.item(F2_fit, 5)
F2.item6 <- extract.item(F2_fit, 6)
F3.item1 <- extract.item(F3_fit, 1)
F3.item2 <- extract.item(F3_fit, 2)
F3.item3 <- extract.item(F3_fit, 3)
F3.item4 <- extract.item(F3_fit, 4)
F3.item5 <- extract.item(F3_fit, 5)
F4.item1 <- extract.item(F4_fit, 1)
F4.item2 <- extract.item(F4_fit, 2)
F4.item3 <- extract.item(F4_fit, 3)
F4.item4 <- extract.item(F4_fit, 4)
F5.item1 <- extract.item(F5_fit, 1)
F5.item2 <- extract.item(F5_fit, 2)
F5.item3 <- extract.item(F5_fit, 3)
F5.item4 <- extract.item(F5_fit, 4)
F5.item5 <- extract.item(F5_fit, 5)


##Item Info
Item16 <- iteminfo(F1.item1, Theta)
Item36 <- iteminfo(F1.item2, Theta)
Item17 <- iteminfo(F1.item3, Theta)
Item11 <- iteminfo(F2.item1, Theta)
Item10 <- iteminfo(F2.item2, Theta)
Item12 <- iteminfo(F2.item3, Theta)
Item07 <- iteminfo(F2.item4, Theta)
Item08 <- iteminfo(F2.item5, Theta)
Item09 <- iteminfo(F2.item6, Theta)
Item27 <- iteminfo(F3.item1, Theta)
Item03 <- iteminfo(F3.item2, Theta)
Item40 <- iteminfo(F3.item3, Theta)
Item30 <- iteminfo(F3.item4, Theta)
Item41 <- iteminfo(F3.item5, Theta)
Item32 <- iteminfo(F4.item1, Theta)
Item35 <- iteminfo(F4.item2, Theta)
Item38 <- iteminfo(F4.item3, Theta)
Item33 <- iteminfo(F4.item4, Theta)
Item46 <- iteminfo(F5.item1, Theta)
Item45 <- iteminfo(F5.item2, Theta)
Item25 <- iteminfo(F5.item3, Theta)
Item04 <- iteminfo(F5.item4, Theta)
Item01 <- iteminfo(F5.item5, Theta)


#Data frame

F1.item.info.data <- as.data.frame(cbind(Item16, 
                                              Item36,
                                              Item17))

F2.item.info.data <- as.data.frame(cbind(Item11, 
                                              Item10,
                                              Item12,
                                         Item07,
                                         Item08,
                                         Item09))

F3.item.info.data <- as.data.frame(cbind(Item27, 
                                              Item03,
                                              Item40,
                                         Item30,
                                        Item41))

F4.item.info.data <- as.data.frame(cbind(Item32, 
                                              Item35,
                                              Item38,
                                         Item33))
F5.item.info.data <- as.data.frame(cbind(Item46, 
                                              Item45,
                                             Item25,
                                         Item04,
                                         Item01))

F1.item.info.data.long <- melt(F1.item.info.data)
F2.item.info.data.long <- melt(F2.item.info.data)
F3.item.info.data.long <- melt(F3.item.info.data)
F4.item.info.data.long <- melt(F4.item.info.data)
F5.item.info.data.long <- melt(F5.item.info.data)

F1.item.info.data.2 <- data.frame(Theta=seq(-6,6, by = .1), F1.item.info.data.long)
F2.item.info.data.2 <- data.frame(Theta=seq(-6,6, by = .1), F2.item.info.data.long)
F3.item.info.data.2 <- data.frame(Theta=seq(-6,6, by = .1), F3.item.info.data.long)
F4.item.info.data.2 <- data.frame(Theta=seq(-6,6, by = .1), F4.item.info.data.long)
F5.item.info.data.2 <- data.frame(Theta=seq(-6,6, by = .1), F5.item.info.data.long)




F1.iic2 <- ggplot(F1.item.info.data.2,aes(Theta,value,col=variable))+geom_line()+apatheme+
  ggtitle("F1 Item Information Plot")+theme(legend.position = "none")+
  labs(y = "Item Information")+facet_wrap(~variable)+theme(strip.text.x = element_text(size = 15))+
  scale_color_npg()+geom_hline(yintercept = .20, colour ="red")+scale_y_continuous(breaks=c(5,50,100,200), limits = c(0, 200))


F2.iic2 <- ggplot(F2.item.info.data.2,aes(Theta,value,col=variable))+geom_line()+apatheme+
  ggtitle("F2 Item Information Plot")+theme(legend.position = "none")+
  labs(y = "Item Information")+facet_wrap(~variable)+theme(strip.text.x = element_text(size = 15))+
  scale_color_npg()+geom_hline(yintercept = .20, colour ="red")


F3.iic2 <- ggplot(F3.item.info.data.2,aes(Theta,value,col=variable))+geom_line()+apatheme+
  ggtitle("F3 Item Information Plot")+theme(legend.position = "none")+
  labs(y = "Item Information")+facet_wrap(~variable)+theme(strip.text.x = element_text(size = 15))+
  scale_color_npg()+geom_hline(yintercept = .20, colour ="red")


F4.iic2 <- ggplot(F4.item.info.data.2,aes(Theta,value,col=variable))+geom_line()+apatheme+
  ggtitle("F4 Item Information Plot")+theme(legend.position = "none")+
  labs(y = "Item Information")+facet_wrap(~variable)+theme(strip.text.x = element_text(size = 15))+
  scale_color_npg()+geom_hline(yintercept = .20, colour ="red")


F5.iic2 <- ggplot(F5.item.info.data.2,aes(Theta,value,col=variable))+geom_line()+apatheme+
  ggtitle("F5 Item Information Plot")+theme(legend.position = "none")+
  labs(y = "Item Information")+facet_wrap(~variable)+theme(strip.text.x = element_text(size = 15))+
  scale_color_npg()+geom_hline(yintercept = .20, colour ="red")




ICC2 <- cowplot::plot_grid(vic.iic2 , agg.iic2,  labels = "AUTO",ncol=2, label_size = 15,align = "v")
ggsave("Figures/ICC2.jpeg",ICC2 , width = 12, height = 8, dpi = 600, bg = "white")
```




```{r IRTparameters, results='asis'}
apa_table(itemparameters, caption = "IRT Item parameters for the LEBA Scale", note = "a = item discrimination parameter; b(1-4) = response category difficulty parameter")
```

```{r shortIRT, include=FALSE}
F1 <- sem.data %>% 
  dplyr::select(item16, item36,  item17)
F2.redu <- sem.data %>% 
  dplyr::select(item11,  item10 , item12, item07, Ritem08, item09)
F3.redu <- sem.data %>% 
 dplyr::select(item27, item03,  item40)

F4.redu <- sem.data %>% 
 dplyr::select(item32, item35,  item33)

F5.redu <- sem.data %>% 
  dplyr::select(item46, item45, item25 )




F1_fit <- mirt(F1, model = 1, itemtype = 'graded', 
               SE = TRUE, Se.type = 'MHRM',
               technical = list(NCYCLES = 10000))

F2_fit.redu <- mirt(F2.redu, model = 1, itemtype = 'graded', SE = TRUE,
               Se.type = 'MHRM',technical = list(NCYCLES = 10000))


F3_fit.redu <- mirt(F3.redu, model = 1, itemtype = 'graded', SE = TRUE,
               Se.type = 'MHRM',technical = list(NCYCLES = 10000))


F4_fit.redu <- mirt(F4.redu, model = 1, itemtype = 'graded', SE = TRUE,
               Se.type = 'MHRM',technical = list(NCYCLES = 10000))

F5_fit.redu <- mirt(F5.redu, model = 1, itemtype = 'graded', SE = TRUE,
               Se.type = 'MHRM',technical = list(NCYCLES = 10000))



#Item fit
F1.item.fit<- itemfit(F1_fit, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)

F2.item.fit<- itemfit(F2_fit.redu, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)
F3.item.fit<- itemfit(F3_fit.redu, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)
F4.item.fit<- itemfit(F4_fit.redu, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)

F5.item.fit<- itemfit(F5_fit.redu, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)


#Itemfit short
#Item fit
F1.item.fit<- itemfit(F1_fit, fit_stats = c("S_X2"),
                                  impute=10)

F2.item.fit<- itemfit(F2_fit.redu, fit_stats = c("S_X2"),
                                  impute=10)
F3.item.fit<- itemfit(F3_fit.redu, fit_stats = c("S_X2"),
                                  impute=10)
F4.item.fit<- itemfit(F4_fit.redu, fit_stats = c("S_X2"),
                                  impute=10)

F5.item.fit<- itemfit(F5_fit.redu, fit_stats = c("S_X2"),
                                  impute=10)

itemfit <- rbind(F1.item.fit,F2.item.fit,F3.item.fit,F4.item.fit,F5.item.fit)

colnames(itemfit) <- c("Item","Signed Chi-square", "df", "RMSEA", "p")

#Identifying Missfit items based on RMSEA Value
F1.item_misfits <- subset(F1.item.fit, RMSEA.S_X2 >= .06)
F2.item_misfits <- subset(F2.item.fit, RMSEA.S_X2 >= .06)
F3.item_misfits <- subset(F3.item.fit, RMSEA.S_X2 >= .06)
F4.item_misfits <- subset(F4.item.fit, RMSEA.S_X2 >= .06)
F5.item_misfits <- subset(F5.item.fit, RMSEA.S_X2 >= .06)


# Person Fit ####
## F1 Person fit ####
F1.personfit <- personfit(F1_fit) 
F1.personfit_model_misfits <- subset(F1.personfit, Zh < -2)
rownames(F1.personfit_model_misfits)
nrow(F1.personfit_model_misfits)

F1.person <- ggplot(F1.personfit, aes(x=Zh)) + geom_histogram(binwidth=.5,col=I("black"),fill=I("grey"))+geom_vline(xintercept = -2)+
  labs( y="Number of Participants", x = "Zh Statistics: F1")+apatheme+ ylim(0,600) + xlim(-4,2)

## F2 Person fit ####
F2.personfit <- personfit(F2_fit.redu) 
F2.personfit_model_misfits <- subset(F2.personfit, Zh < -2)
rownames(F2.personfit_model_misfits)
nrow(F2.personfit_model_misfits)


F2.person <- ggplot(F2.personfit, aes(x=Zh)) + geom_histogram(binwidth=.5, col=I("black"),fill=I("grey"))+
  scale_x_continuous(limits = c(-5, 1))+geom_vline(xintercept = -2)+
  labs( y="Number of Participants", x = "Zh Statistics: F2")+apatheme+ylim(0,600) + xlim(-4,2)



## F3 Person fit ####
F3.personfit <- personfit(F3_fit.redu) 
F3.personfit_model_misfits <- subset(F3.personfit, Zh < -2)
rownames(F3.personfit_model_misfits)
nrow(F3.personfit_model_misfits)


F3.person <- ggplot(F3.personfit, aes(x=Zh)) + geom_histogram(binwidth=.5, col=I("black"),fill=I("grey"))+geom_vline(xintercept = -2)+
  labs( y="Number of Participants", x = "Zh Statistics: F3")+apatheme+ylim(0,600) + xlim(-4,2)


## F4 Person fit ####
F4.personfit <- personfit(F4_fit.redu) 
F4.personfit_model_misfits <- subset(F4.personfit, Zh < -2)
rownames(F4.personfit_model_misfits)
nrow(F4.personfit_model_misfits)


F4.person <- ggplot(F4.personfit, aes(x=Zh)) + geom_histogram(binwidth=.5, col=I("black"),fill=I("grey"))+geom_vline(xintercept = -2)+
  labs( y="Number of Participants", x = "Zh Statistics: F4")+apatheme+ylim(0,600) + xlim(-4,2)


## F5 Person fit ####
F5.personfit <- personfit(F5_fit) 
F5.personfit_model_misfits <- subset(F5.personfit, Zh < -2)
rownames(F3.personfit_model_misfits)
nrow(F5.personfit_model_misfits)

F5.person <- ggplot(F5.personfit, aes(x=Zh)) + geom_histogram(binwidth=.5, col=I("black"),fill=I("grey"))+geom_vline(xintercept = -2)+
  labs( y="Number of Participants", x = "Zh Statistics:F5")+apatheme+ylim(0,600) + xlim(-4,2)

# Model Parameters ####
## F1 Model Parameters####
F1_params <- coef(F1_fit, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
F1_items.redu <- data.frame(F1_params$items)
F1l_se <- coef(F1_fit, printSE = TRUE)

## F2 Model Parameters####
F2_params <- coef(F2_fit.redu, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
F2_items.redu <- data.frame(F2_params$items)
F2_se <- coef(F2_fit.redu, printSE = TRUE)

## F3 Model Parameters####
F3_params <- coef(F3_fit.redu, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
F3_items.redu <- data.frame(F3_params$items)
F3_se <- coef(F3_fit.redu, printSE = TRUE)

## F4 Model Parameters####
F4_params <- coef(F4_fit.redu, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
F4_items.redu <- data.frame(F4_params$items)
F4_se <- coef(F4_fit.redu, printSE = TRUE)

## F5 Model Parameters####
F5_params <- coef(F5_fit.redu, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
F5_items.redu<- data.frame(F5_params$items)
F5_se.redu <- coef(F5_fit.redu, printSE = TRUE)






F1.reliability <- plot(F1_fit, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )
F2.reliability <- plot(F2_fit.redu, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )
F3.reliability <- plot(F3_fit.redu, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )
F4.reliability <- plot(F4_fit.redu, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )
F5.reliability <- plot(F5_fit, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )

##IRT reliability (marginal reliability of scales)
F1.marginal.rel <- marginal_rxx(F1_fit)
F2.marginal.rel <-marginal_rxx(F2_fit.redu)
F3.marginal.rel <-marginal_rxx(F3_fit.redu)
F4.marginal.rel <-marginal_rxx(F4_fit.redu)
F5.marginal.rel <-marginal_rxx(F5_fit)





# Plots2 ####

F1_test.info <- plot(F1_fit, type = "infoSE", main = "F1: Wearing blue light filters") 

F2_test.info.redu <- plot(F2_fit.redu, type = "infoSE", main = "F2: Spending time outdoors")


F3_test.info.redu <- plot(F3_fit.redu, type = "infoSE", main = "F3: Using phone and smart-watch in bed")

F4_test.info.redu <- plot(F4_fit.redu, type = "infoSE", main = "F4: Using light before bedtime")

F5_test.info <- plot(F5_fit.redu, type = "infoSE", main = "F5: Using light in the morning and during daytime")




##Scale characteristic curve
F1.scale <- plot(F1_fit, type = 'score', theta_lim = c(-6, 6), main = "")
F2.scale <- plot(F2_fit.redu, type = 'score', theta_lim = c(-6, 6), main = "")
F3.scale <- plot(F3_fit.redu, type = 'score', theta_lim = c(-6, 6), main = "")
F4.scale <- plot(F4_fit.redu, type = 'score', theta_lim = c(-6, 6), main = "")
F5.scale <- plot(F5_fit.redu, type = 'score', theta_lim = c(-6, 6), main = "")

```


```{r testinfoggplot2, include=F}
Theta <- matrix(seq(-6,6, by = .1))

F1.T1 <- 0
for(i in 1:ncol(F1)){
  F1.T1 <- F1.T1 + iteminfo(extract.item(F1_fit, i), Theta)
}

F2.T1 <- 0
for(i in 1:ncol(F2.redu)){
  F2.T1 <- F2.T1 + iteminfo(extract.item(F2_fit.redu, i), Theta)
}

F3.T1 <- 0
for(i in 1:ncol(F3.redu)){
  F3.T1 <- F3.T1 + iteminfo(extract.item(F3_fit.redu, i), Theta)
}

F4.T1 <- 0
for(i in 1:ncol(F4.redu)){
  F4.T1 <- F4.T1 + iteminfo(extract.item(F4_fit.redu, i), Theta)
}

F5.T1 <- 0
for(i in 1:ncol(F5.redu)){
  F5.T1 <- F5.T1 + iteminfo(extract.item(F5_fit.redu, i), Theta)
}



F1.test.data <- as.data.frame(cbind(Theta, F1.T1))

F2.test.data <- as.data.frame(cbind(Theta, F2.T1))

F3.test.data <- as.data.frame(cbind(Theta, F3.T1))

F4.test.data <- as.data.frame(cbind(Theta, F4.T1))

F5.test.data <- as.data.frame(cbind(Theta, F5.T1))



F1.tic <- ggplot(F1.test.data, aes(x=Theta, y=F1.T1)) +
  geom_line()+apatheme+
  labs(y="Test Information", title = "F1 Test Inforfamtion")+scale_color_brewer(palette="Dark2")

F2.tic <- ggplot(F2.test.data, aes(x=Theta, y=F2.T1)) +
  geom_line()+apatheme+
  labs(y="Test Information", title = "F2 Test Inforfamtion")+ylim(0,8)

F3.tic <- ggplot(F3.test.data, aes(x=Theta, y=F3.T1)) +
  geom_line()+apatheme+
  labs(y="Test Information", title = "F3 Test Inforfamtion")+ylim(0,6)

F4.tic <- ggplot(F4.test.data, aes(x=Theta, y=F4.T1)) +
  geom_line()+apatheme+
  labs(y="Test Information", title = "F4 Test Inforfamtion")

F5.tic <- ggplot(F5.test.data, aes(x=Theta, y=F5.T1)) +
  geom_line()+apatheme+
  labs(y="Test Information", title = "F5 Test Inforfamtion") +ylim(0,6)


#panel TIC

TIC <- cowplot::plot_grid(F1.tic,F2.tic, F3.tic,
                                   F4.tic,F5.tic,
                   labels = "AUTO",
                     align="v",
                     ncol = 2,
                     label_size = 15,
                     label_fontfamily = "Arial",
                     label_fontface = "plain")
ggsave("Manuscript.figures/TIC.png",TIC, width = 10, height = 12, dpi = 600, bg = "white")

```


```{r Testinfo, fig.cap="Test information curves (a) Wearing blue light filters (b) Spending time outdoors (c) Using phone and smartwatchin bed (d) Using light before bedtime (e) Using light in the morning andduring daytime", warning=FALSE}

knitr::include_graphics('Manuscript.figures/TIC.png', dpi =600)
```

Test information curve (TIC) (Figure \@ref(fig:Testinfo)) indicate the amount of information an the full-scale carry along the latent trait continuum. As we treated each factor of short-LEBA as an unidmensional construct we obtain 5 TICs (Figure \@ref(fig:Testinfo)). These information curves indicated except the first and fifth factors, the other three factor's TICs are roughly centered on the center of the trait continuum ($\theta$).The first and fifth factor had a peak to the right side of the center of latent trait.Thus we conferred the LEBA tool estimated the light exposure related behavior with precision near the center of trait continuum for 2nd, 3rd and 4th factors and near the right side of the center of trait continuum for 1st and 5th factors [@bakerBasicsItemResponse2017].

Table \@ref(tab:itemfittab) summarizes the item fit indexes of the items. All the items fitted well to the respective models as assessed by  RMSEA value obtained from Signed-$\chi^2$ index implementation. All of the items had RMSEA value $\le$.06 indicating adequate fit. Sup.Figure \@ref(fig:personfit) depicts the person fit of out fitted models. Person fit indicates the validity and meaningfulness of the fitted model at the participants latent trait level [@desjardinsHandbookEducationalMeasurement2018]. We estimated the person fit statistics using standardized fit index Zh statistics [@drasgow1985appropriateness]. Zh < -2 should be considered as a misfit. Fig indicates that Zh is larger than -2 for most participants, suggesting a good fit of the selected IRT models. 

```{r itemfittab, results='asis',warning=F, message=F}
apa_table(itemfit, caption ="Item fit statistics for the fitted models")
```

```{r perfit, include=F}
personfit <- plot_grid(F1.person, F2.person,F3.person,F4.person,F5.person, 
          labels = "AUTO", label_size = 12,align = "v", ncol =2,
                       label_fontfamily = "Arial",
                     label_fontface = "plain")


ggsave("Manuscript.figures/personfit.png",personfit , width = 10, height = 12, dpi = 600, bg = "white")

```



```{r scalechar, eval=FALSE, fig.cap="Scale characteristic curve of the five fitted IRT models (a) Wearing blue light filters (b) Spending time outdoors (c) Using phone and smartwatchin bed (d) Using light before bedtime (e) Using light in the morning andduring daytime", warning=FALSE, include=FALSE, out.height="120%", out.width="100%"}
#not used in the manuscript

#Finally we generated scale characteristics curve (Figure \@ref(fig:scalechar)) which plotted estimated theta score against the expected true score. The purpose of this scale characteristics curve is to find the corresponding expected true score for the given estimated theta score of the participants. 


plot_grid(F1.scale, F1.scale,F1.scale,F1.scale,F1.scale, 
          labels = "AUTO", label_size = 10,align = "v")
```



```{r fscore, include=FALSE}
LEBA.Total <- sem.data %>% 
  rowwise() %>% 
  mutate(F1.Total = sum(item16, item36,  item17))



LEBA.Total <- LEBA.Total %>% 
  rowwise() %>% 
  mutate(F2.Total = sum(item11,  item10 , item12, item07, Ritem08, item09))


LEBA.Total <- LEBA.Total %>% 
  rowwise() %>% 
  mutate(F3.Total = sum(item27, item03,  item40))

LEBA.Total <- LEBA.Total %>% 
  rowwise() %>% 
  mutate(F4.Total = sum(item32, item35,  item33))

LEBA.Total <- LEBA.Total %>% 
  rowwise() %>% 
  mutate(F5.Total = sum(item46, item45, item25))



F1.estimation <- as.vector(fscores(F1_fit, method = "EAP",
                                           full.scores = TRUE, 
                                           full.scores.SE = F))


F2.estimation <- as.vector(fscores(F2_fit.redu, method = "EAP",
                                           full.scores = TRUE, 
                                           full.scores.SE = F))

F3.estimation <- as.vector(fscores(F3_fit.redu, method = "EAP",
                                           full.scores = TRUE, 
                                           full.scores.SE = F))

F4.estimation <- as.vector(fscores(F4_fit.redu, method = "EAP",
                                           full.scores = TRUE, 
                                           full.scores.SE = F))

F5.estimation <- as.vector(fscores(F5_fit, method = "EAP",
                                           full.scores = TRUE, 
                                           full.scores.SE = F))





Ability.F1 <- data.frame(Rawscore = LEBA.Total$F1.Total,
                      Theta =  F1.estimation)



Ability.F2 <- data.frame(Rawscore = LEBA.Total$F2.Total,
                      Theta =  F2.estimation)

Ability.F3 <- data.frame(Rawscore = LEBA.Total$F3.Total,
                      Theta =  F3.estimation)

Ability.F4 <- data.frame(Rawscore = LEBA.Total$F3.Total,
                      Theta =  F3.estimation)

Ability.F5 <- data.frame(Rawscore = LEBA.Total$F3.Total,
                      Theta =  F3.estimation)




ggplot(Ability.F1, aes(x =Theta, y =Rawscore)) +
  geom_point() +
  geom_smooth(method='lm', se =TRUE, formula= y~x,colour = "red")+
  xlim(-2,2) +
  ylim(0,15)


ggplot(Ability.F2, aes(x =Theta, y =Rawscore)) +
  geom_point() +
  geom_smooth(method='lm', se =TRUE, formula= y~x,colour = "red")+
  xlim(-2,2) +
  ylim(0,15)



ggplot(Ability.F3, aes(x =Theta, y =Rawscore)) +
  geom_point() +
  geom_smooth(method='lm', se =TRUE, formula= y~x,colour = "red")+
  xlim(-2,2) +
  ylim(0,15)

ggplot(Ability.F4, aes(x =Theta, y =Rawscore)) +
  geom_point() +
  geom_smooth(method='lm', se =TRUE, formula= y~x,colour = "red")+
  xlim(-2,2) +
  ylim(0,15)


ggplot(Ability.F5, aes(x =Theta, y =Rawscore)) +
  geom_point() +
  geom_smooth(method='lm', se =TRUE, formula= y~x,colour = "red")+
  xlim(-2,2) +
  ylim(0,15)


Score.correation <- cbind(Ability.F1,Ability.F2, Ability.F3, Ability.F4, Ability.F5)
colnames(Score.correation) <- c("F1.Raw", "F1.Estimated","F2.Raw", "F2.Estimated","F3.Raw", "F3.Estimated","F4.Raw", "F4.Estimated","F5.Raw", "F5.Estimated")

F1.cor <- corr.test(Score.correation$F1.Raw, Score.correation$F1.Estimated)

F2.cor <- corr.test(Score.correation$F2.Raw, Score.correation$F2.Estimated)

F3.cor <- corr.test(Score.correation$F3.Raw, Score.correation$F3.Estimated)

F4.cor <- corr.test(Score.correation$F4.Raw, Score.correation$F4.Estimated)

F5.cor <- corr.test(Score.correation$F5.Raw, Score.correation$F5.Estimated)


#Putting significance star for correlation
F1.p <-F1.cor$p
F1.stars <- ifelse(F1.p < .001, "***"
                   , ifelse(p < .01, "**"
                            , ifelse(p < .05, "*"
                                     , ifelse(p < .10, "+", " "))))


F2.p <-F2.cor$p
F2.stars <- ifelse(F2.p < .001, "**"
                   , ifelse(p < .01, "**"
                            , ifelse(p < .05, "*"
                                     , ifelse(p < .10, "+", " "))))


F3.p <-F3.cor$p
F3.stars <- ifelse(F3.p < .001, "***"
                   , ifelse(p < .01, "**"
                            , ifelse(p < .05, "*"
                                     , ifelse(p < .10, "+", " "))))

F4.p <-F4.cor$p
F4.stars <- ifelse(F4.p < .001, "***"
                   , ifelse(p < .01, "**"
                            , ifelse(p < .05, "*"
                                     , ifelse(p < .10, "+", " "))))

F5.p <-F5.cor$p
F5.stars <- ifelse(F5.p < .001, "***"
                   , ifelse(p < .01, "**"
                            , ifelse(p < .05, "*"
                                     , ifelse(p < .10, "+", " "))))


theta.correlation.matrix <- matrix("NA", nrow =1, ncol = 5)

theta.correlation.matrix[1,1] <- paste(apa(F1.cor$r,2,F), F1.stars,sep="")
theta.correlation.matrix[1,2] <- paste(apa(F2.cor$r,2,F), F2.stars,sep="")
theta.correlation.matrix[1,3] <- paste(apa(F3.cor$r,2,F), F3.stars,sep="")
theta.correlation.matrix[1,4] <- paste(apa(F4.cor$r,2,F), F4.stars,sep="")
theta.correlation.matrix[1,5] <- paste(apa(F5.cor$r,2,F), F5.stars,sep="")


as.data.frame(theta.correlation.matrix)
colnames(theta.correlation.matrix) <- c("F1", "F2", "F3", "F4", "F5")
```

```{r WPdata, warning=F, include=FALSE}

library(RColorBrewer)
F1.e <- as.data.frame(F1.estimation)
F2.e <- as.data.frame(F2.estimation)
F3.e <- as.data.frame(F3.estimation)
F4.e <- as.data.frame(F4.estimation)
F5.e <- as.data.frame(F5.estimation)

estimation <- as.data.frame(cbind(F1.e,F2.e,F3.e,F4.e,F5.e))




threshold <- rbind(F1_items.redu[,2:5],
                   F2_items.redu[,2:5],
                   F3_items.redu[,2:5],
                   F4_items.redu[,2:5],
                   F5_items.redu[,2:5])


itemlevelcolors <- matrix(rep(brewer.pal(4, "Set1"), 18), byrow = TRUE, ncol = 4)

```

```{r saveWrightmao, include=FALSE, warning=F, message=F}
jpeg("Manuscript.figures/wm.png", width = 800, height = 750)
WrightMap::wrightMap(estimation, threshold, 
          item.prop = 0.65,
          
          main.title = "LEBA",
          dim.names = c("F1", "F2", "F3", "F4", "F5"),
          thr.sym.col.fg = itemlevelcolors,
          thr.sym.col.bg = itemlevelcolors,
          vertLines = TRUE,
          show.thr.lab = T,
          dim.color = brewer.pal(5, "Set3"))
dev.off()
```

```{r WP, eval=FALSE, fig.cap="Person Item Map", warning=FALSE, include=FALSE, out.height="120%", out.width="100%"}

knitr::include_graphics('Manuscript.figures/wm.png')
```

```{r IRTscoreCor, eval=FALSE, include=FALSE, results='asis'}
apa_table (theta.correlation.matrix, caption = "correlation coefficents of obtained scores and estimated latent trait for each factots", note = "* p < 0.05; ** p < 0.01; *** p < 0.001"  )
```

# Discussion

We developed a self-reported tool to capture different light exposure related behavior and evaluated its psychometric properties using classical test theory and item response theory based analysis. 

48 items were generated by an expert panel and  administered to a large sample (n = `r nrow(EFA.descriptives)` to explore the latent structure. Exploratory factor analysis revealed a five factor solution with 25 items. ("Wearing blue light filters", "Spending time outdoors", "Using phone and smart-watch in bed", "Using light before bedtime",  and "Using light in the morning and during daytime"). The internal consistency reliability coefficient ordinal alpha ranged between `r apa(range(alpha.tab),2,F)`. As all the retained factors were meaningful and contributed essentially towards our aim we retained all five factors.


A CFA on a separate sample ((n = `r nrow(CFA.descriptives)` gave a five-factor solution (CFI =`r apa(fit.2[5],2,F)`; TLI = `r apa(fit.2[6],2,F)`); RMSEA = `r apa(fit.2[7],2,F)`[`r apa(fit.2[8],2,F)`-`r apa(fit.2[9],2,F)`, 90% CI]) and SRMR = `r apa(fit.2[10],2,F)`) after discarding two item. The internal consistency McDonald's $\omega_t$ of the five factors were  satisfactory (`r apa(rel.k[2,1],2,F)`, `r apa(rel.k[2,2],2,F)`, `r apa(rel.k[2,3],2,F)`, `r apa(rel.k[2,4],2,F)`, `r apa(rel.k[2,5],2,F)`) Internal consistency reliability of the total scale (23 items) was also satisfactory, McDonald's $\omega_t$= `r apa(rel.k[5,6],2,F)`.  In the same sample, our measurement invariance analysis  revealed that the latent structure attained the residual measurement invariance across subgroups: male and female (CFI: `r apa (residual.fitm[5,1],2,F)`, TLI: `r apa (residual.fitm[6,1],2,F)`, SRMR: `r apa (residual.fitm[6,1],2,F)`).

The "Semantic Scale Network"(SSN) analysis [@rosenbusch2020semantic] on the retained 23 items showed "LEBA" was  related to  "Sleep Disturbance Scale For Children" (SDSC) [@bruni1996sleep] and "WHO-Composite International Diagnostic Interview (CIDI): Insomnia"[@who1990]. Upon inspecting the item contents we found items under "Using phone and smart-watch in bed" and "Using light before bedtime" have semantic overlap with the items of SDSC ans CIDI. Items in those two scales were looking into behaviors related to sleep. As such the similarity index obtained is expected. Flesch-Kincaid Grade Level [@flesch1948new] analysis on the the 23 items of our scale indicated required educational grade level was 3.33 and with a age above 8.33.

Lastly, we developed a short-LEBA (n=23) using IRT analysis. We fitted a graded response model model to the combined EFA and CFA sample (n =`r nrow(data)`). We discarded 5 items with relatively flat item information curve [I($\theta$) <.20]. IRT analysis indicated short form of LEBA is a psychometrically sound measure. Item fit indexes and person fit index for all five fitted model were acceptable. Items had diverse slope parameters indicating a good range of discrimination- the ability to differentiate respondents with different levels of the light exposure related behavior. Test information curve also indicated a good coverage of underlying trait continuum with precision.

## Conclusion
"The Light exposure behavior assessment"(LEBA) gave a five solution with 25 items in an exploratory factor analysis. A confirmatory factor analysis with this 25-item scale again offered a five-factor solution, but this time two more item was discarded. The 23-item "LEBA" was found reliable and valid. A short-form of LEBA was developed using IRT analysis. IRT analysis gave a 18-item scale with  a good range of coverage across the underlying trait continuum. All-in-all, we can recommend both forms to be used to capture individual’s light exposure related behavior

\newpage

# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

```{=tex}
\endgroup
```


