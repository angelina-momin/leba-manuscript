---
title: "Appendix B"
author: "Team LEBA"
date: "10/22/2021"
output: pdf_document
---

## Supplimentary Analysis

```{r setupAppB, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = F, message = F, dpi=600)
set.seed(123)
par(family = "Helvetica")
```

```{r libraryAppB, include=FALSE}

library(papaja) # devtools::install_github("crsh/papaja")
library(lavaan)
library(semPlot) #devtools::install_github('SachaEpskamp/semPlot',  dependencies = T)
library(semTools)
library(MOTE)
library(car)#revercoding 
library(psych)
library(dlookr)
library(plyr)
library(tidyverse)
library(qgraph)
library(kableExtra)
library(paran) # Parallel analysis
library(EFA.MRFA) # Hull method
library(DiagrammeR) #devtools::install_github('rich-iannone/DiagrammeR')
library(DiagrammeRsvg) #For DiagrammeR
library(rsvg) #For DiagrammeR
library(ggcorrplot)
library(semTable)
library(magick)
library(mirt)
library(gtsummary)
library(gt)
library(gtExtras)
library(likert)
library(VIM) #Missing data
library(kutils)
library(Hmisc)
library(extrafont)
extrafont::font_import()

```

```{r DataAppB, include=FALSE}
data <- readRDS("leba_2021-09-08.rds")


#Separating the EFA and CFA(only items)
sem.data <- data[, 9:56] #EFA & CFA data
## renaming the column-header
prefix <- "item"
sufix <- c(1:48)
colnam <- paste(prefix,sufix, sep = "" )
colnames(sem.data) <- colnam
EFA.data <- sem.data[1:428, ]


```

```{r ggplot2AppB, include=F}
apatheme=theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        text=element_text(family = "Helvetica",),
        legend.title=element_blank(),
        axis.line.x = element_line(color='black'),
        axis.line.y = element_line(color='black'),
        panel.border = element_rect(color = "black",
                                    fill = NA,
                                    size = 1))
```

```{r EFAassumptionsAppB, include=FALSE}

#KMO test
KMO <- KMO(EFA.data) 

# Test of correlation matrix
bartlet <- cortest.bartlett(EFA.data, n =428)


# Univariate normality

#creating normality function
shapiro_test_df <- function(df, bonf= TRUE, alpha= 0.05) {
  l <- lapply(df, shapiro.test)
  s <- do.call("c", lapply(l, "[[", 1))
  p <- do.call("c", lapply(l, "[[", 2))
  if (bonf == TRUE) {
    sig <- ifelse(p > alpha / length(l), "H0", "*")
  } else {
    sig <- ifelse(p > alpha, "H0", "*")
  }
  return(list(statistic= s,
              p.value= p,
              significance= sig,
              method= ifelse(bonf == TRUE, "Shapiro-Wilks test with Bonferroni Correction","Shapiro-Wilks test without Bonferroni Correction")))
}


Shapiro.efa <- shapiro_test_df(EFA.data)


efa.normality.tab = matrix(nrow = 48, ncol = 2)
rownameprefix <- "Item"
rownamesufix <- seq(1:48)
my.item.names <- paste(rownameprefix,rownamesufix, sep = "" )
rownames(efa.normality.tab) <- my.item.names
colnames(efa.normality.tab) <- c("statistic", "p")

efa.normality.tab[,1] <- apa(Shapiro.efa$statistic,2,T)
efa.normality.tab[,2] <- apa(Shapiro.efa$p.value,2,T)

efa.normalityprefix <- efa.normality.tab[,1]
efa.normalitysufix <- Shapiro.efa$significance
efa.normality.stat <- paste(efa.normalityprefix,efa.normalitysufix, sep = "" )

# Multivariate Normality
mardia <- mardia(EFA.data, na.rm = T, plot =F)

# Descriptive Stats
Descriptives <- psych::describe(EFA.data)
alpha <- psych::alpha(EFA.data)
Item.total <- alpha$item.stats

Des.combined <- cbind(apa(Descriptives$mean,2,T), apa(Descriptives$sd,2,T), apa(Descriptives$skew,2,T),apa(Descriptives$kurtosis,2,T), efa.normality.stat,  apa(Item.total$r.cor,2,F))

colnames(Des.combined) = c("Mean", "SD", "Skew", "Kurtosis", "Shapiro-Wilk Statistics","Item-Total Correlation")
rownameprefix <- "Item"
rownamesufix <- seq(1:48)
my.names <- paste(rownameprefix,rownamesufix, sep = "" )
rownames(Des.combined) = (my.names)
```

```{r tabDesAppB, results='asis'}
apa_table(Des.combined, caption = "Descriptive Statistics for Unmerged response options", align = "c", note = "*p<.001", placement = "h")
```

```{r CorrMatrixAppB, include=FALSE}
#Polychoric Correlation matrix

correlations <- polychoric(EFA.data, correct = 0)
upper <- correlations$rho[upper.tri(correlations$rho, diag = F)]

min.cor <- abs(min(upper)) #minimum cor.coefficient of the matrix
max.cor <- abs(max(upper)) # max. correlation coefficient of the matrix

determinets <- det(correlations$rho) 
# Calculating the percentage of correlations higher than .30

BigR = sum(correlations$rho >= abs(.30) & correlations$rho < abs(1.0), na.rm =T)/2 
totR = length(EFA.data)*(length(EFA.data)-1)/2
cor.per <- print (BigR/totR)*100
```

```{r figCorAppB, fig.align='center', fig.cap="Correlation plot of the items",  out.width="100%"}

ggcorrplot(correlations$rho, hc.order = TRUE, outline.col = "white", type = "lower", 
           ggtheme = ggplot2::theme_minimal, tl.cex = 6,tl.srt = 90 )
#p.mat <- cor_to_p(correlations$rho, 428, method = "polychoric")
#to show pvalue in the fig add p.mat=p.mat
```

```{r ParallelEFAAppB, include=FALSE}

# Parallel analysis
Horn <- paran(correlations$rho, iterations=500, centile=0, quietly=FALSE,
           status=TRUE, all=FALSE, cfa=FALSE, graph=TRUE,
           color=TRUE, col=c("black","red","blue"),
           lty=c(1,2,3), lwd=1, legend=TRUE, 
           width=640, height=640, grdevice=png, seed=0, mat=NA, n=NA)


Adjusted.EV <- data.frame(Horn$AdjEv)
Adjusted.EV$type = c('Adjusted Ev')
Adjusted.EV$num = c(row.names(Adjusted.EV))
Adjusted.EV$num = as.numeric(Adjusted.EV$num)
colnames(Adjusted.EV) = c('eigenvalue', 'type', 'num')


Random.EV <- data.frame(Horn$RndEv)
Random.EV$type = c('Random EV')
Random.EV$num = c(row.names(Random.EV))
Random.EV$num = as.numeric(Random.EV$num)
colnames(Random.EV) = c('eigenvalue', 'type', 'num')


Unadjusted.EV <- data.frame(Horn$Ev)
Unadjusted.EV$type = c('Unadjusted EV')
Unadjusted.EV$num = c(row.names(Unadjusted.EV))
Unadjusted.EV$num = as.numeric(Unadjusted.EV$num)
colnames(Unadjusted.EV) = c('eigenvalue', 'type', 'num')



parallel = ggplot(Adjusted.EV, aes(x=num, y=eigenvalue, shape=type, color=type)) +
  #Add lines connecting data points
  geom_line()+
    geom_line(data = Random.EV) +
  geom_line(data = Unadjusted.EV)+
    #Add the data points.
  geom_point(size=1)+
  geom_point(data = Random.EV, size=1)+
  geom_point(data = Unadjusted.EV, size=1)+
  scale_y_continuous(name="Eigen Value", limits=c(0, 10), breaks=seq(0,10,2)) +
   #Label the x-axis 'Factor Number', and ensure that it ranges from 1-max # of factors, increasing by one with each 'tick' mark.
  scale_x_continuous(name='Factor Number', limits=c(0, 48),breaks=seq(0,48,4))+
    #Add vertical line indicating parallel analysis suggested max # of factors to retain
  geom_hline(yintercept=1, linetype = 'dashed') + apatheme 

```

```{r ScreePlotAppB, include=FALSE}
Scree <- scree(correlations$rho,factors=TRUE,pc=TRUE,main="(B)",
      hline=NULL,add=F)


FA.Scree <- data.frame(Scree$fv)
FA.Scree$type = c('Factor Analysis')
FA.Scree$num = c(row.names(FA.Scree))
FA.Scree$num = as.numeric(FA.Scree$num)
colnames(FA.Scree) = c('eigenvalue', 'type', 'num')

PA.Scree <- data.frame(Scree$pcv)
PA.Scree$type = c('Principal Component Analysis')
PA.Scree$num = c(row.names(PA.Scree))
PA.Scree$num = as.numeric(PA.Scree$num)
colnames(PA.Scree) = c('eigenvalue', 'type', 'num')


scree.plot <-ggplot(FA.Scree, aes(x=num, y=eigenvalue,color=type, shape=type))+
   geom_line()+
  geom_line(data = PA.Scree)+ 
  geom_point(size=1)+
  geom_point(data = PA.Scree, size=1)+
  scale_y_continuous(name="Eigen Value", limits=c(0, 10), breaks=seq(0,10,2)) +
  scale_x_continuous(name='Factor Number', limits=c(0, 48),breaks=seq(0,48,4))+
  geom_hline(yintercept=1, linetype = 'dashed') + apatheme 
```

```{r MAPefaAppB, include=FALSE}
#MAP
psych::VSS(EFA.data, rotate = "varimax", fm = 'minres', n.obs =428 )
```

```{r facIdFigAppB, fig.align='center', fig.cap='Factor Identification (A) Parallel analysis (B) Scree Plot', warning=FALSE,  out.height="100%", out.width="100%"}
cowplot::plot_grid(parallel, scree.plot, labels = "AUTO",ncol=1, label_size = 8,align = "v")

```

Horn's parallel analysis with 500 iterations indicated a five-factor solution. However, Scree plot and the MAP method suggested 6-factor solution. five-factor solution . As a result, we tested both five-factor and six-factor solutions.

```{r EFAAppB, include=FALSE}
fa.5F.1 <- fa(r=correlations$rho, nfactors = 5, fm= "pa",rotate ="varimax",
              residuals = TRUE, SMC = TRUE, n.obs =428)
AA <- print(fa.5F.1, cut = .3, digits = 3, sort = TRUE)


reduced.model.5F.1 <- dplyr::select(EFA.data ,
                                    -c(item32, item34, item24, item37, item22, item5,
                                        item28, item30, item39,item23, item45, item6, item29, item2, item41))

correlations.red.5F.1 <- polychoric(reduced.model.5F.1,correct = 0)

fa.5F.2 <- fa(r=correlations.red.5F.1$rho, nfactors = 5, fm= "pa",rotate ="varimax",
              residuals = TRUE, SMC = TRUE, n.obs =428)

BB <- print(fa.5F.2, cut = .3, digits = 3, sort = TRUE)

reduced.model.5F.2 <- dplyr::select(EFA.data, -c( item32, item34, item24, item37, item22, item5,
                                        item28, item30, item39,item23, item45, item6, item29, item2, item41, item46, item13, item15, item25, item1, item26, item14))

correlations.red.5F.2 <- polychoric(reduced.model.5F.2,correct = 0)


fa.5F.3 <- fa(r=correlations.red.5F.2$rho, nfactors = 5, fm= "pa",rotate ="varimax",
              residuals = TRUE, SMC = TRUE, n.obs =428,max.iter = 500 )

CC <- print(fa.5F.3, cut = .3, digits = 3, sort = TRUE)

reduced.model.5F.3 <- dplyr::select(EFA.data, -c( item32, item34, item24, item37, item22, item5,
                                        item28, item30, item39,item23, item45, item6, item29, item2, item41, item46, item13, item15, item25, item1, item26, item14, item43, item42))

correlations.red.5F.3 <- polychoric(reduced.model.5F.3,correct = 0)


fa.5F.4 <- fa(r=correlations.red.5F.3$rho, nfactors = 5, fm= "pa",rotate ="varimax",
              residuals = TRUE, SMC = TRUE, n.obs =428,max.iter = 500 )

CC <- print(fa.5F.4, cut = .3, digits = 3, sort = TRUE)
```

```{r factordetailsAppB, include=FALSE}
#Preparing the EFA table
library(data.table)
fa_table <- function(x, cut) {
  #get sorted loadings
  loadings <- fa.sort(x)$loadings %>% round(2)
  #supress loadings
  loadings[abs(loadings) < abs(cut)] <- ""
  #get additional info
  add_info <- cbind(x$communality, 
                    x$uniquenesses,
                    x$complexity) %>%
    # make it a data frame
    as.data.frame() %>%
    # column names
    rename("Communality" = V1,
           "Uniqueness" = V2,
           "Complexity" = V3) %>%
    #get the item names from the vector
    rownames_to_column("item")
  #build table
  loadings <- loadings %>%
    unclass() %>%
    as.data.frame() %>%
    rownames_to_column("item") %>%
    left_join(add_info) %>%
    mutate(across(where(is.numeric), round, 3)) %>% 
    as.data.frame()
  variance <- x$Vaccounted %>% 
  as.data.frame()%>% 
  round(2)
  loadings <- rbind(setDT(loadings), setDT(variance[2,]), fill=TRUE)
  
}

efa.table <- fa_table(fa.5F.4,.3) 
nr <- nrow(efa.table)
efa.table[nr, 1] <- "% of Variance"

#Communality
Fac.5 <- fa.5F.4
min.com <- min(Fac.5$communality)
max.com <- max(Fac.5$communality)

# loading
min.loadings <- min(Fac.5$loadings)
max.loadings <- max(Fac.5$loadings)

# Residuals
residual.5F =residuals(fa.5F.4, diag = FALSE, na.rm =T)
#Count of numbers of residuals>.05
BigRR= sum(residual.5F>abs(.05), na.rm =T)
print(BigRR)

#Total number of off diagonal elements in the data matrix
totRR = length(reduced.model.5F.3)*(length(reduced.model.5F.3)-1)/2

# Proportion of off-diagonal elements >.10
sumR <- sum(BigRR/totRR*100)


```

```{r EFATableAppB, results='asis'}

apa_table(efa.table,align = "c", caption = "Factor loadings and communality of the retained items [Unmerged Responses]", note = "Only loading higher than .30 is reported", font_size = "small", placement = "h")
```

| **Five Factor Solution[Unmerged Responses] (24 Items)** |
|---------------------------------------------------------|
| **F1**                                                  |
| `r label(sem.data$item19)`                              |
| `r label(sem.data$item20)`                              |
| `r label(sem.data$item18)`                              |
| `r label(sem.data$item21)`                              |
| `r label(sem.data$item4)`                               |
| **F2**                                                  |
| `r label(sem.data$item11)`                              |
| `r label(sem.data$item10)`                              |
| `r label(sem.data$item12)`                              |
| `r label(sem.data$item8)`                               |
| `r label(sem.data$item7)`                               |
| `r label(sem.data$item9)`                               |
| **F3**                                                  |
| `r label(sem.data$item3)`                               |
| `r label(sem.data$item27)`                              |
| `r label(sem.data$item40)`                              |
| **F4**                                                  |
| `r label(sem.data$item35)`                              |
| `r label(sem.data$item48)`                              |
| `r label(sem.data$item33)`                              |
| `r label(sem.data$item47)`                              |
| `r label(sem.data$item44)`                              |
| `r label(sem.data$item31)`                              |
| `r label(sem.data$item38)`                              |
| **F5**                                                  |
| `r label(sem.data$item16)`                              |
| `r label(sem.data$item17)`                              |
| `r label(sem.data$item36)`                              |

```{r EFAResidualsAppB, eval=FALSE, fig.align='center', fig.cap=' Histogram of residulas:  five-factor solution', warning=FALSE, include=FALSE,  results='asis'}
hist(residual.5F,  main = NULL, xlab = "Five-factor solution", ylim=c(0, 400))
abline(h =35, lwd = 2, lty = 2)
abline(v =.05,lwd = 2, lty = 2)

```
